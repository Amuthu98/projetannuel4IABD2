{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.datasets import *\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '.ipynb_checkpoints', '2014', '2015', '2016', '2017', '2018', 'All_years', 'Data_API.ipynb', 'Data_Test_Foot.csv', 'Data_Train_Foot.csv', 'Points_Equipe_Hist', 'Points_Equipe_Hist_VF', 'Recup_Data_Historical.ipynb', 'Teams_puiss.csv', 'Web_Score.ipynb']\n",
      "C:\\Users\\Amrta\\Documents\\GitHub\\projetannuel4IABD2\\ETAPE_3\\Scripts_Recup_Data\\Projet_Annuel_Data\\Data_Test_Foot.csv\n"
     ]
    }
   ],
   "source": [
    "main_path=\"C:\\\\Users\\\\Amrta\\\\Documents\\\\GitHub\\\\projetannuel4IABD2\\\\ETAPE_3\\\\Scripts_Recup_Data\\\\\"\n",
    "open_folder = os.listdir(main_path)\n",
    "Data_base_learning = main_path+open_folder[3]\n",
    "Data_base_learning_v2 = main_path+open_folder[4]\n",
    "path2 = \"C:\\\\Users\\\\Amrta\\\\Documents\\\\GitHub\\\\projetannuel4IABD2\\\\ETAPE_3\\\\Scripts_Recup_Data\\\\Projet_Annuel_Data\\\\\"\n",
    "open_folder1= os.listdir(path2)\n",
    "Data_train = path2+open_folder1[10]\n",
    "Data_test = path2+open_folder1[9]\n",
    "print(open_folder1)\n",
    "print(Data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>homeTeam</th>\n",
       "      <th>awayTeam</th>\n",
       "      <th>score</th>\n",
       "      <th>goalHomeTeam_FullTime</th>\n",
       "      <th>goalAwayTeam_FullTime</th>\n",
       "      <th>goalHomeTeam_HalfTime</th>\n",
       "      <th>goalAwayTeam_HalfTime</th>\n",
       "      <th>NbgoalsHalfTime</th>\n",
       "      <th>...</th>\n",
       "      <th>moy_goals_home</th>\n",
       "      <th>moy_goals_away</th>\n",
       "      <th>moy_goals_half_home</th>\n",
       "      <th>moy_goals_half_away</th>\n",
       "      <th>moy_goals_conceded_home</th>\n",
       "      <th>moy_goals_conceded_away</th>\n",
       "      <th>moy_goals_conceded_half_home</th>\n",
       "      <th>moy_goals_conceded_half_away</th>\n",
       "      <th>puissance_HomeTeam</th>\n",
       "      <th>puissance_AwayTeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-09 00:00:00</td>\n",
       "      <td>AS Monaco FC</td>\n",
       "      <td>Olympique Lyonnais</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2409</td>\n",
       "      <td>6154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-10 00:00:00</td>\n",
       "      <td>Olympique de Marseille</td>\n",
       "      <td>Stade de Reims</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4008</td>\n",
       "      <td>3054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-10 00:00:00</td>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>Stade Rennais FC 1901</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3029</td>\n",
       "      <td>4815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-10 00:00:00</td>\n",
       "      <td>OGC Nice</td>\n",
       "      <td>Amiens SC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2803</td>\n",
       "      <td>2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-08-10 00:00:00</td>\n",
       "      <td>Stade Brestois 29</td>\n",
       "      <td>Toulouse FC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2156</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11514</td>\n",
       "      <td>375</td>\n",
       "      <td>2018-05-19</td>\n",
       "      <td>Villarreal</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370370</td>\n",
       "      <td>2.814815</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>1.439153</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>1.037037</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.433862</td>\n",
       "      <td>6451</td>\n",
       "      <td>15239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11515</td>\n",
       "      <td>376</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>Ath Bilbao</td>\n",
       "      <td>Espanol</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.306878</td>\n",
       "      <td>1.164021</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.497354</td>\n",
       "      <td>1.164021</td>\n",
       "      <td>1.412698</td>\n",
       "      <td>0.544974</td>\n",
       "      <td>0.656085</td>\n",
       "      <td>4273</td>\n",
       "      <td>5802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11516</td>\n",
       "      <td>377</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>Ath Madrid</td>\n",
       "      <td>Eibar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.724868</td>\n",
       "      <td>1.253968</td>\n",
       "      <td>0.693122</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.640212</td>\n",
       "      <td>1.407407</td>\n",
       "      <td>0.232804</td>\n",
       "      <td>0.640212</td>\n",
       "      <td>13709</td>\n",
       "      <td>4725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11517</td>\n",
       "      <td>378</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Sociedad</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.920635</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>1.105820</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>1.391534</td>\n",
       "      <td>0.349206</td>\n",
       "      <td>0.640212</td>\n",
       "      <td>14840</td>\n",
       "      <td>4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11518</td>\n",
       "      <td>379</td>\n",
       "      <td>2018-05-20</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>La Coruna</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.539683</td>\n",
       "      <td>1.074074</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.539683</td>\n",
       "      <td>1.306878</td>\n",
       "      <td>1.677249</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>8716</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11519 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                 date                homeTeam  \\\n",
       "0               0  2019-08-09 00:00:00            AS Monaco FC   \n",
       "1               1  2019-08-10 00:00:00  Olympique de Marseille   \n",
       "2               2  2019-08-10 00:00:00         Montpellier HSC   \n",
       "3               3  2019-08-10 00:00:00                OGC Nice   \n",
       "4               4  2019-08-10 00:00:00       Stade Brestois 29   \n",
       "...           ...                  ...                     ...   \n",
       "11514         375           2018-05-19              Villarreal   \n",
       "11515         376           2018-05-20              Ath Bilbao   \n",
       "11516         377           2018-05-20              Ath Madrid   \n",
       "11517         378           2018-05-20               Barcelona   \n",
       "11518         379           2018-05-20                Valencia   \n",
       "\n",
       "                    awayTeam  score  goalHomeTeam_FullTime  \\\n",
       "0         Olympique Lyonnais    2.0                    0.0   \n",
       "1             Stade de Reims    2.0                    0.0   \n",
       "2      Stade Rennais FC 1901    2.0                    0.0   \n",
       "3                  Amiens SC    1.0                    2.0   \n",
       "4                Toulouse FC    0.0                    1.0   \n",
       "...                      ...    ...                    ...   \n",
       "11514            Real Madrid    0.0                    2.0   \n",
       "11515                Espanol    2.0                    0.0   \n",
       "11516                  Eibar    0.0                    2.0   \n",
       "11517               Sociedad    1.0                    1.0   \n",
       "11518              La Coruna    1.0                    2.0   \n",
       "\n",
       "       goalAwayTeam_FullTime  goalHomeTeam_HalfTime  goalAwayTeam_HalfTime  \\\n",
       "0                        3.0                    0.0                    2.0   \n",
       "1                        2.0                    0.0                    0.0   \n",
       "2                        1.0                    0.0                    1.0   \n",
       "3                        1.0                    1.0                    0.0   \n",
       "4                        1.0                    1.0                    0.0   \n",
       "...                      ...                    ...                    ...   \n",
       "11514                    2.0                    0.0                    2.0   \n",
       "11515                    1.0                    0.0                    1.0   \n",
       "11516                    2.0                    1.0                    1.0   \n",
       "11517                    0.0                    0.0                    0.0   \n",
       "11518                    1.0                    1.0                    0.0   \n",
       "\n",
       "       NbgoalsHalfTime  ...  moy_goals_home  moy_goals_away  \\\n",
       "0                  2.0  ...        0.000000        0.000000   \n",
       "1                  0.0  ...        0.000000        0.000000   \n",
       "2                  1.0  ...        0.000000        0.000000   \n",
       "3                  1.0  ...        0.000000        0.000000   \n",
       "4                  1.0  ...        0.000000        0.000000   \n",
       "...                ...  ...             ...             ...   \n",
       "11514              2.0  ...        1.370370        2.814815   \n",
       "11515              1.0  ...        1.306878        1.164021   \n",
       "11516              2.0  ...        1.724868        1.253968   \n",
       "11517              0.0  ...        2.920635        1.444444   \n",
       "11518              1.0  ...        1.539683        1.074074   \n",
       "\n",
       "       moy_goals_half_home  moy_goals_half_away  moy_goals_conceded_home  \\\n",
       "0                 0.000000             0.000000                 0.000000   \n",
       "1                 0.000000             0.000000                 0.000000   \n",
       "2                 0.000000             0.000000                 0.000000   \n",
       "3                 0.000000             0.000000                 0.000000   \n",
       "4                 0.000000             0.000000                 0.000000   \n",
       "...                    ...                  ...                      ...   \n",
       "11514             0.613757             1.439153                 0.984127   \n",
       "11515             0.587302             0.497354                 1.164021   \n",
       "11516             0.693122             0.608466                 0.640212   \n",
       "11517             1.105820             0.682540                 0.809524   \n",
       "11518             0.730159             0.539683                 1.306878   \n",
       "\n",
       "       moy_goals_conceded_away  moy_goals_conceded_half_home  \\\n",
       "0                     0.000000                      0.000000   \n",
       "1                     0.000000                      0.000000   \n",
       "2                     0.000000                      0.000000   \n",
       "3                     0.000000                      0.000000   \n",
       "4                     0.000000                      0.000000   \n",
       "...                        ...                           ...   \n",
       "11514                 1.037037                      0.396825   \n",
       "11515                 1.412698                      0.544974   \n",
       "11516                 1.407407                      0.232804   \n",
       "11517                 1.391534                      0.349206   \n",
       "11518                 1.677249                      0.571429   \n",
       "\n",
       "       moy_goals_conceded_half_away  puissance_HomeTeam  puissance_AwayTeam  \n",
       "0                          0.000000                2409                6154  \n",
       "1                          0.000000                4008                3054  \n",
       "2                          0.000000                3029                4815  \n",
       "3                          0.000000                2803                2045  \n",
       "4                          0.000000                2156                1065  \n",
       "...                             ...                 ...                 ...  \n",
       "11514                      0.433862                6451               15239  \n",
       "11515                      0.656085                4273                5802  \n",
       "11516                      0.640212               13709                4725  \n",
       "11517                      0.640212               14840                4571  \n",
       "11518                      0.740741                8716                 100  \n",
       "\n",
       "[11519 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(Data_train,sep=\";\",encoding=\"utf-8\")\n",
    "display(train_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,  2409,  6154],\n",
       "       [    0,     0,     0,     0,  4008,  3054],\n",
       "       [    0,     0,     0,     0,  3029,  4815],\n",
       "       ...,\n",
       "       [    1,     2,     0,     0, 13709,  4725],\n",
       "       [    0,     1,     1,     0, 14840,  4571],\n",
       "       [    1,     0,     0,     1,  8716,   100]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns={'win_cons_home':train_csv.win_cons_home,'win_cons_away':train_csv.win_cons_away,'lose_cons_home':train_csv.lose_cons_home,'lose_cons_away':train_csv.lose_cons_away,'puissance_HomeTeam':train_csv.puissance_HomeTeam,'puissance_AwayTeam':train_csv.puissance_AwayTeam}\n",
    "df = pd.DataFrame(train_columns)\n",
    "X = df.values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       ...,\n",
       "       [1, 2],\n",
       "       [0, 1],\n",
       "       [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_columns={'win_cons_home':train_csv.win_cons_home,'win_cons_away':train_csv.win_cons_away}\n",
    "df1 = pd.DataFrame(y_train_columns)\n",
    "Y= df1.values\n",
    "Y\n",
    "# Y = train_csv['win_cons_home':train_csv.win_cons_home].values\n",
    "# Y[0]\n",
    "# Y = train_csv['score'].values\n",
    "# X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9215, 6) (9215, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_validation, y_train, y_validation =train_test_split(X,Y, test_size=0.2)\n",
    "print(x_train.shape,y_train.shape)\n",
    "y_train = y_train.astype(int)\n",
    "y_validation = y_validation.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     1,     0,     0,   100,   100],\n",
       "       [    0,     5,     2,     0,  3398, 12219],\n",
       "       [    0,     0,     1,     0,  4967,  3373],\n",
       "       ...,\n",
       "       [    0,     1,     7,     0,   100,   889],\n",
       "       [    1,     1,     0,     0,  3029,  4207],\n",
       "       [    0,     0,     1,     0,  3048,  4928]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(6, input_dim=x_train.shape[1], activation='relu'))\n",
    "#     model.add(Dense(6, activation='softmax'))\n",
    "#     model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "#                   optimizer=Adam(),\n",
    "#                   metrics=[\"accuracy\"])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(2, input_dim=6, activation=\"relu\"))\n",
    "    model.add(Dense(2,activation = \"softmax\"))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 2)                 14        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = ModelCheckpoint('model_score_exact_mi_temps.h5', monitor = 'val_accuracy' , verbose = 1 , save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9215 samples, validate on 2304 samples\n",
      "Epoch 1/100\n",
      "8100/9215 [=========================>....] - ETA: 0s - loss: 3.3328WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 2s 168us/sample - loss: 3.2964 - val_loss: 2.9068\n",
      "Epoch 2/100\n",
      "8730/9215 [===========================>..] - ETA: 0s - loss: 3.2148WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 3.2184 - val_loss: 2.8263\n",
      "Epoch 3/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 3.1557WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 30us/sample - loss: 3.1795 - val_loss: 2.8149\n",
      "Epoch 4/100\n",
      "7470/9215 [=======================>......] - ETA: 0s - loss: 3.2874WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 40us/sample - loss: 3.1676 - val_loss: 2.8018\n",
      "Epoch 5/100\n",
      "8100/9215 [=========================>....] - ETA: 0s - loss: 3.1730WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 3.1646 - val_loss: 2.7975\n",
      "Epoch 6/100\n",
      "8640/9215 [===========================>..] - ETA: 0s - loss: 3.1338WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 30us/sample - loss: 3.1575 - val_loss: 2.7935\n",
      "Epoch 7/100\n",
      "7290/9215 [======================>.......] - ETA: 0s - loss: 3.1318WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 37us/sample - loss: 3.1498 - val_loss: 2.7845\n",
      "Epoch 8/100\n",
      "8640/9215 [===========================>..] - ETA: 0s - loss: 3.1463WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 33us/sample - loss: 3.1527 - val_loss: 2.7904\n",
      "Epoch 9/100\n",
      "9180/9215 [============================>.] - ETA: 0s - loss: 3.1396WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 29us/sample - loss: 3.1396 - val_loss: 2.7737\n",
      "Epoch 10/100\n",
      "8280/9215 [=========================>....] - ETA: 0s - loss: 3.1467WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 3.1380 - val_loss: 2.7765\n",
      "Epoch 11/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 3.1145WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 42us/sample - loss: 3.1411 - val_loss: 2.7779\n",
      "Epoch 12/100\n",
      "8640/9215 [===========================>..] - ETA: 0s - loss: 3.1114WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 33us/sample - loss: 3.1396 - val_loss: 2.7753\n",
      "Epoch 13/100\n",
      "8820/9215 [===========================>..] - ETA: 0s - loss: 2.9788WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 30us/sample - loss: 2.9818 - val_loss: 2.4453\n",
      "Epoch 14/100\n",
      "7920/9215 [========================>.....] - ETA: 0s - loss: 2.6605WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.8349 - val_loss: 2.4493\n",
      "Epoch 15/100\n",
      "9000/9215 [============================>.] - ETA: 0s - loss: 2.8223WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 41us/sample - loss: 2.8341 - val_loss: 2.4423\n",
      "Epoch 16/100\n",
      "7920/9215 [========================>.....] - ETA: 0s - loss: 2.8692WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 31us/sample - loss: 2.8339 - val_loss: 2.4418\n",
      "Epoch 17/100\n",
      "7740/9215 [========================>.....] - ETA: 0s - loss: 2.8509WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 30us/sample - loss: 2.8328 - val_loss: 2.4418\n",
      "Epoch 18/100\n",
      "8100/9215 [=========================>....] - ETA: 0s - loss: 2.8513WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 34us/sample - loss: 2.8322 - val_loss: 2.4409\n",
      "Epoch 19/100\n",
      "8910/9215 [============================>.] - ETA: 0s - loss: 2.8699WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.8329 - val_loss: 2.4475\n",
      "Epoch 20/100\n",
      "9000/9215 [============================>.] - ETA: 0s - loss: 2.8070WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 28us/sample - loss: 2.8303 - val_loss: 2.4419\n",
      "Epoch 21/100\n",
      "8730/9215 [===========================>..] - ETA: 0s - loss: 2.8265WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 29us/sample - loss: 2.8303 - val_loss: 2.4386\n",
      "Epoch 22/100\n",
      "7560/9215 [=======================>......] - ETA: 0s - loss: 2.7770WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 33us/sample - loss: 2.8288 - val_loss: 2.4371\n",
      "Epoch 23/100\n",
      "9000/9215 [============================>.] - ETA: 0s - loss: 2.8373WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.8259 - val_loss: 2.4379\n",
      "Epoch 24/100\n",
      "8190/9215 [=========================>....] - ETA: 0s - loss: 2.7992WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 34us/sample - loss: 2.8249 - val_loss: 2.4317\n",
      "Epoch 25/100\n",
      "8370/9215 [==========================>...] - ETA: 0s - loss: 2.8351WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 34us/sample - loss: 2.8247 - val_loss: 2.4399\n",
      "Epoch 26/100\n",
      "8460/9215 [==========================>...] - ETA: 0s - loss: 2.8639WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 30us/sample - loss: 2.8114 - val_loss: 2.4644\n",
      "Epoch 27/100\n",
      "7290/9215 [======================>.......] - ETA: 0s - loss: 2.8130WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 37us/sample - loss: 2.8001 - val_loss: 2.4106\n",
      "Epoch 28/100\n",
      "7830/9215 [========================>.....] - ETA: 0s - loss: 2.8363WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.7743 - val_loss: 2.3887\n",
      "Epoch 29/100\n",
      "9000/9215 [============================>.] - ETA: 0s - loss: 2.7606WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 31us/sample - loss: 2.7434 - val_loss: 2.3406\n",
      "Epoch 30/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 2.7399WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 39us/sample - loss: 2.7336 - val_loss: 2.3291\n",
      "Epoch 31/100\n",
      "8460/9215 [==========================>...] - ETA: 0s - loss: 2.7321WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.7156 - val_loss: 2.3197\n",
      "Epoch 32/100\n",
      "8280/9215 [=========================>....] - ETA: 0s - loss: 2.6918WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 33us/sample - loss: 2.7000 - val_loss: 2.3026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "7470/9215 [=======================>......] - ETA: 0s - loss: 2.5919WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 34us/sample - loss: 2.6874 - val_loss: 2.3041\n",
      "Epoch 34/100\n",
      "7920/9215 [========================>.....] - ETA: 0s - loss: 2.7055WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 39us/sample - loss: 2.6819 - val_loss: 2.3301\n",
      "Epoch 35/100\n",
      "8280/9215 [=========================>....] - ETA: 0s - loss: 2.6961WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.6738 - val_loss: 2.2827\n",
      "Epoch 36/100\n",
      "7200/9215 [======================>.......] - ETA: 0s - loss: 2.6001WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 34us/sample - loss: 2.6635 - val_loss: 2.2839\n",
      "Epoch 37/100\n",
      "7560/9215 [=======================>......] - ETA: 0s - loss: 2.6550WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.6563 - val_loss: 2.2866\n",
      "Epoch 38/100\n",
      "8460/9215 [==========================>...] - ETA: 0s - loss: 2.6791WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 2.6632 - val_loss: 2.2686\n",
      "Epoch 39/100\n",
      "7830/9215 [========================>.....] - ETA: 0s - loss: 2.7029- ETA: 0s - loss: 2.669WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 2.6801 - val_loss: 2.2654\n",
      "Epoch 40/100\n",
      "7830/9215 [========================>.....] - ETA: 0s - loss: 2.6345WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 33us/sample - loss: 2.6489 - val_loss: 2.2650\n",
      "Epoch 41/100\n",
      "8010/9215 [=========================>....] - ETA: 0s - loss: 2.6128WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.6390 - val_loss: 2.2609\n",
      "Epoch 42/100\n",
      "8370/9215 [==========================>...] - ETA: 0s - loss: 2.6901WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.6335 - val_loss: 2.2597\n",
      "Epoch 43/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 2.6075WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 37us/sample - loss: 2.6282 - val_loss: 2.2521\n",
      "Epoch 44/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 2.6207WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 2.6227 - val_loss: 2.2487\n",
      "Epoch 45/100\n",
      "7380/9215 [=======================>......] - ETA: 0s - loss: 2.6254WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 40us/sample - loss: 2.6194 - val_loss: 2.2490\n",
      "Epoch 46/100\n",
      "7740/9215 [========================>.....] - ETA: 0s - loss: 2.7038WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 37us/sample - loss: 2.6146 - val_loss: 2.2819\n",
      "Epoch 47/100\n",
      "7200/9215 [======================>.......] - ETA: 0s - loss: 2.5286WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.6152 - val_loss: 2.2414\n",
      "Epoch 48/100\n",
      "8820/9215 [===========================>..] - ETA: 0s - loss: 2.6022WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 39us/sample - loss: 2.6096 - val_loss: 2.2414\n",
      "Epoch 49/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 2.6198WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.6096 - val_loss: 2.2325\n",
      "Epoch 50/100\n",
      "7650/9215 [=======================>......] - ETA: 0s - loss: 2.4810WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 33us/sample - loss: 2.6066 - val_loss: 2.2364\n",
      "Epoch 51/100\n",
      "8550/9215 [==========================>...] - ETA: 0s - loss: 2.5907WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 38us/sample - loss: 2.6020 - val_loss: 2.2547\n",
      "Epoch 52/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 2.6200WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.6048 - val_loss: 2.2276\n",
      "Epoch 53/100\n",
      "7290/9215 [======================>.......] - ETA: 0s - loss: 2.5921WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 31us/sample - loss: 2.5984 - val_loss: 2.2314\n",
      "Epoch 54/100\n",
      "8190/9215 [=========================>....] - ETA: 0s - loss: 2.5811WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 31us/sample - loss: 2.5929 - val_loss: 2.2215\n",
      "Epoch 55/100\n",
      "7290/9215 [======================>.......] - ETA: 0s - loss: 2.6188WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 33us/sample - loss: 2.5948 - val_loss: 2.2188\n",
      "Epoch 56/100\n",
      "8370/9215 [==========================>...] - ETA: 0s - loss: 2.5929WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 2.5922 - val_loss: 2.2157\n",
      "Epoch 57/100\n",
      "7200/9215 [======================>.......] - ETA: 0s - loss: 2.6074WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 28us/sample - loss: 2.5850 - val_loss: 2.2148\n",
      "Epoch 58/100\n",
      "8640/9215 [===========================>..] - ETA: 0s - loss: 2.5754WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 31us/sample - loss: 2.5820 - val_loss: 2.2119\n",
      "Epoch 59/100\n",
      "8190/9215 [=========================>....] - ETA: 0s - loss: 2.6193WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 30us/sample - loss: 2.5784 - val_loss: 2.2088\n",
      "Epoch 60/100\n",
      "8100/9215 [=========================>....] - ETA: 0s - loss: 2.6053WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 37us/sample - loss: 2.5753 - val_loss: 2.2100\n",
      "Epoch 61/100\n",
      "7560/9215 [=======================>......] - ETA: 0s - loss: 2.5581WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 28us/sample - loss: 2.5819 - val_loss: 2.2055\n",
      "Epoch 62/100\n",
      "6570/9215 [====================>.........] - ETA: 0s - loss: 2.6365WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 27us/sample - loss: 2.5719 - val_loss: 2.2027\n",
      "Epoch 63/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 2.5881WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 30us/sample - loss: 2.5689 - val_loss: 2.2061\n",
      "Epoch 64/100\n",
      "8010/9215 [=========================>....] - ETA: 0s - loss: 2.6081WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 29us/sample - loss: 2.5691 - val_loss: 2.2016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "9180/9215 [============================>.] - ETA: 0s - loss: 2.5566WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 2.5661 - val_loss: 2.1999\n",
      "Epoch 66/100\n",
      "7560/9215 [=======================>......] - ETA: 0s - loss: 2.6768WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 2.5650 - val_loss: 2.1959\n",
      "Epoch 67/100\n",
      "8100/9215 [=========================>....] - ETA: 0s - loss: 2.6306WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.5614 - val_loss: 2.1923\n",
      "Epoch 68/100\n",
      "7560/9215 [=======================>......] - ETA: 0s - loss: 2.5755WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 38us/sample - loss: 2.5581 - val_loss: 2.2032\n",
      "Epoch 69/100\n",
      "8370/9215 [==========================>...] - ETA: 0s - loss: 2.5655WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.5609 - val_loss: 2.1919\n",
      "Epoch 70/100\n",
      "9000/9215 [============================>.] - ETA: 0s - loss: 2.5729WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 2.5569 - val_loss: 2.1940\n",
      "Epoch 71/100\n",
      "8550/9215 [==========================>...] - ETA: 0s - loss: 2.4342WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 39us/sample - loss: 2.5572 - val_loss: 2.1868\n",
      "Epoch 72/100\n",
      "7920/9215 [========================>.....] - ETA: 0s - loss: 2.5795WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 31us/sample - loss: 2.5537 - val_loss: 2.1906\n",
      "Epoch 73/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 2.5207WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.5541 - val_loss: 2.1844\n",
      "Epoch 74/100\n",
      "8820/9215 [===========================>..] - ETA: 0s - loss: 2.5402WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 37us/sample - loss: 2.5511 - val_loss: 2.1840\n",
      "Epoch 75/100\n",
      "8910/9215 [============================>.] - ETA: 0s - loss: 2.5433WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 38us/sample - loss: 2.5539 - val_loss: 2.1715\n",
      "Epoch 76/100\n",
      "9000/9215 [============================>.] - ETA: 0s - loss: 2.4753WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 29us/sample - loss: 2.5104 - val_loss: 2.1412\n",
      "Epoch 77/100\n",
      "9180/9215 [============================>.] - ETA: 0s - loss: 2.5054WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 2.5018 - val_loss: 2.1493\n",
      "Epoch 78/100\n",
      "7740/9215 [========================>.....] - ETA: 0s - loss: 2.4913WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 34us/sample - loss: 2.5037 - val_loss: 2.1406\n",
      "Epoch 79/100\n",
      "7290/9215 [======================>.......] - ETA: 0s - loss: 2.5047WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 38us/sample - loss: 2.5036 - val_loss: 2.1393\n",
      "Epoch 80/100\n",
      "7650/9215 [=======================>......] - ETA: 0s - loss: 2.4633WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.4986 - val_loss: 2.1374\n",
      "Epoch 81/100\n",
      "8010/9215 [=========================>....] - ETA: 0s - loss: 2.4537WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 33us/sample - loss: 2.4971 - val_loss: 2.1356\n",
      "Epoch 82/100\n",
      "8640/9215 [===========================>..] - ETA: 0s - loss: 2.4703WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 40us/sample - loss: 2.4955 - val_loss: 2.1357\n",
      "Epoch 83/100\n",
      "8820/9215 [===========================>..] - ETA: 0s - loss: 2.5174WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 30us/sample - loss: 2.4980 - val_loss: 2.1379\n",
      "Epoch 84/100\n",
      "7110/9215 [======================>.......] - ETA: 0s - loss: 2.5509WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 28us/sample - loss: 2.4970 - val_loss: 2.1382\n",
      "Epoch 85/100\n",
      "9090/9215 [============================>.] - ETA: 0s - loss: 2.5178WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 36us/sample - loss: 2.5034 - val_loss: 2.1334\n",
      "Epoch 86/100\n",
      "8370/9215 [==========================>...] - ETA: 0s - loss: 2.4714WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.4938 - val_loss: 2.1330\n",
      "Epoch 87/100\n",
      "8280/9215 [=========================>....] - ETA: 0s - loss: 2.5887WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 30us/sample - loss: 2.4931 - val_loss: 2.1364\n",
      "Epoch 88/100\n",
      "8100/9215 [=========================>....] - ETA: 0s - loss: 2.5321WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 33us/sample - loss: 2.4920 - val_loss: 2.1324\n",
      "Epoch 89/100\n",
      "8280/9215 [=========================>....] - ETA: 0s - loss: 2.4775WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 35us/sample - loss: 2.4951 - val_loss: 2.1319\n",
      "Epoch 90/100\n",
      "8910/9215 [============================>.] - ETA: 0s - loss: 2.4423WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 40us/sample - loss: 2.4918 - val_loss: 2.1320\n",
      "Epoch 91/100\n",
      "6930/9215 [=====================>........] - ETA: 0s - loss: 2.4993WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 28us/sample - loss: 2.4959 - val_loss: 2.1317\n",
      "Epoch 92/100\n",
      "7920/9215 [========================>.....] - ETA: 0s - loss: 2.4633WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 27us/sample - loss: 2.4976 - val_loss: 2.1304\n",
      "Epoch 93/100\n",
      "8460/9215 [==========================>...] - ETA: 0s - loss: 2.5074WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 31us/sample - loss: 2.4909 - val_loss: 2.1306\n",
      "Epoch 94/100\n",
      "9180/9215 [============================>.] - ETA: 0s - loss: 2.4792WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 34us/sample - loss: 2.4947 - val_loss: 2.1308\n",
      "Epoch 95/100\n",
      "7470/9215 [=======================>......] - ETA: 0s - loss: 2.6088WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 34us/sample - loss: 2.4899 - val_loss: 2.1297\n",
      "Epoch 96/100\n",
      "8550/9215 [==========================>...] - ETA: 0s - loss: 2.5254WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.4899 - val_loss: 2.1309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "8550/9215 [==========================>...] - ETA: 0s - loss: 2.4918WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 32us/sample - loss: 2.4904 - val_loss: 2.1342\n",
      "Epoch 98/100\n",
      "9180/9215 [============================>.] - ETA: 0s - loss: 2.4942WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 41us/sample - loss: 2.4926 - val_loss: 2.1306\n",
      "Epoch 99/100\n",
      "8550/9215 [==========================>...] - ETA: 0s - loss: 2.5402WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 31us/sample - loss: 2.5066 - val_loss: 2.1460\n",
      "Epoch 100/100\n",
      "7470/9215 [=======================>......] - ETA: 0s - loss: 2.4753WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "9215/9215 [==============================] - 0s 34us/sample - loss: 2.4917 - val_loss: 2.1293\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,validation_data=(x_validation,y_validation),batch_size=90,epochs=100,callbacks = [save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Amrta\\\\Documents\\\\GitHub\\\\projetannuel4IABD2\\\\ETAPE_3\\\\Scripts_Recup_Data\\\\Projet_Annuel_Data\\\\Data_Test_Foot.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_csv = pd.read_csv(Data_test,sep=\";\",encoding=\"utf-8\")\n",
    "display(Data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 MSE:1.9246\n",
      "y2 MSE:2.3340\n"
     ]
    }
   ],
   "source": [
    "ypred = model.predict(x_test)\n",
    "print(\"y1 MSE:%.4f\" % mean_squared_error(y_test[:,0], ypred[:,0])) \n",
    "print(\"y2 MSE:%.4f\" % mean_squared_error(y_test[:,1], ypred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-0649829918ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_ax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_ax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y1-test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_ax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y1-pred\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_ax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y2-test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_ax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y2-pred\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "x_ax = range(len(x_test))\n",
    "plt.scatter(x_ax, y_test[:,0],  s=6, label=\"y1-test\")\n",
    "plt.plot(x_ax, ypred[:,0], label=\"y1-pred\")\n",
    "plt.scatter(x_ax, y_test[:,1],  s=6, label=\"y2-test\")\n",
    "plt.plot(x_ax, ypred[:,1], label=\"y2-pred\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    1    2 4146 7311]\n",
      "[0 0]\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[255])\n",
    "print(y_test[255])\n",
    "plt.show()\n",
    "preds = model.predict((x_test, y_test))\n",
    "print(preds[255])\n",
    "# np.argmax(predictions[98])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PrÃ©diction Unique mi-temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puissance_homeTeam = 0\n",
    "puissance_awayTeam = 4523998\n",
    "win_cons_home = -1\n",
    "win_cons_away = -1\n",
    "lose_cons_home = -1\n",
    "lose_cons_away= -1\n",
    "predictions1 = model.predict(np.array([[win_cons_home,win_cons_away,lose_cons_home,lose_cons_away,puissance_homeTeam,puissance_awayTeam]])) # predictions avec puissance de teams au hasard\n",
    "predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]] 2409 6154\n",
      "[[1. 0.]] 4008 3054\n",
      "[[1. 0.]] 3029 100\n",
      "[[1. 0.]] 2803 2045\n",
      "[[1. 0.]] 2156 1065\n",
      "[[1. 0.]] 2690 2298\n",
      "[[1. 0.]] 100 3749\n",
      "[[1. 0.]] 4207 3029\n",
      "[[1. 0.]] 3627 1736\n",
      "[[1. 0.]] 9495 2020\n",
      "[[1. 0.]] 6154 2690\n",
      "[[1. 0.]] 3029 4008\n",
      "[[1. 0.]] 2298 3029\n",
      "[[1. 0.]] 1065 100\n",
      "[[1. 0.]] 2020 2803\n",
      "[[1. 0.]] 1736 2409\n",
      "[[1. 0.]] 2045 4207\n",
      "[[1. 0.]] 3749 2156\n",
      "[[1. 0.]] 3054 3627\n",
      "[[1. 0.]] 100 9495\n",
      "[[1. 0.]] 2156 3054\n",
      "[[1. 0.]] 2690 1736\n",
      "[[1. 0.]] 100 2298\n",
      "[[1. 0.]] 2045 3029\n",
      "[[1. 0.]] 2409 2020\n",
      "[[1. 0.]] 3627 100\n",
      "[[1. 0.]] 9495 1065\n",
      "[[1. 0.]] 3029 6154\n",
      "[[1. 0.]] 4207 3749\n",
      "[[1. 0.]] 2803 4008\n",
      "[[1. 0.]] 1736 9495\n",
      "[[1. 0.]] 6154 2298\n",
      "[[1. 0.]] 1065 2045\n",
      "[[1. 0.]] 2690 100\n",
      "[[1. 0.]] 3029 3029\n",
      "[[1. 0.]] 2020 2156\n",
      "[[1. 0.]] 100 2803\n",
      "[[1. 0.]] 3054 4207\n",
      "[[1. 0.]] 3627 2409\n",
      "[[1. 0.]] 4008 3749\n",
      "[[1. 0.]] 4207 2690\n",
      "[[1. 0.]] 2045 6154\n",
      "[[1. 0.]] 9495 3627\n",
      "[[1. 0.]] 3029 2803\n",
      "[[1. 0.]] 2298 1736\n",
      "[[1. 0.]] 2156 100\n",
      "[[1. 0.]] 100 2020\n",
      "[[1. 0.]] 3029 3054\n",
      "[[1. 0.]] 3749 1065\n",
      "[[1. 0.]] 2409 4008\n",
      "[[1. 0.]] 3627 3029\n",
      "[[1. 0.]] 4008 3029\n",
      "[[1. 0.]] 2298 2156\n",
      "[[1. 0.]] 2803 100\n",
      "[[1. 0.]] 3054 2409\n",
      "[[1. 0.]] 2020 1065\n",
      "[[1. 0.]] 1736 2045\n",
      "[[1. 0.]] 100 4207\n",
      "[[1. 0.]] 2690 3749\n",
      "[[1. 0.]] 6154 9495\n",
      "[[1. 0.]] 100 4008\n",
      "[[1. 0.]] 2409 2803\n",
      "[[1. 0.]] 3029 2020\n",
      "[[1. 0.]] 4207 3627\n",
      "[[1. 0.]] 3749 1736\n",
      "[[1. 0.]] 1065 2690\n",
      "[[1. 0.]] 2156 6154\n",
      "[[1. 0.]] 3029 100\n",
      "[[1. 0.]] 2045 2298\n",
      "[[1. 0.]] 9495 3054\n",
      "[[1. 0.]] 6154 3029\n",
      "[[1. 0.]] 2298 9495\n",
      "[[1. 0.]] 2803 4207\n",
      "[[1. 0.]] 3054 100\n",
      "[[1. 0.]] 2690 2045\n",
      "[[1. 0.]] 2409 2156\n",
      "[[1. 0.]] 1736 1065\n",
      "[[1. 0.]] 3627 3029\n",
      "[[1. 0.]] 2020 3749\n",
      "[[1. 0.]] 4008 100\n",
      "[[1. 0.]] 2045 4008\n",
      "[[1. 0.]] 9495 2690\n",
      "[[1. 0.]] 3029 2409\n",
      "[[1. 0.]] 1065 2298\n",
      "[[1. 0.]] 2156 1736\n",
      "[[1. 0.]] 3029 2803\n",
      "[[1. 0.]] 100 3627\n",
      "[[1. 0.]] 4207 2020\n",
      "[[1. 0.]] 100 3054\n",
      "[[1. 0.]] 3749 6154\n",
      "[[1. 0.]] 2803 9495\n",
      "[[1. 0.]] 6154 100\n",
      "[[1. 0.]] 1065 4207\n",
      "[[1. 0.]] 3054 3029\n",
      "[[1. 0.]] 2690 2156\n",
      "[[1. 0.]] 2020 2045\n",
      "[[1. 0.]] 1736 3029\n",
      "[[1. 0.]] 2298 3749\n",
      "[[1. 0.]] 2409 100\n",
      "[[1. 0.]] 4008 3627\n",
      "[[1. 0.]] 3029 2409\n",
      "[[1. 0.]] 4207 2298\n",
      "[[1. 0.]] 3029 2690\n",
      "[[1. 0.]] 6154 1736\n",
      "[[1. 0.]] 2156 100\n",
      "[[1. 0.]] 3054 2020\n",
      "[[1. 0.]] 3627 2803\n",
      "[[1. 0.]] 100 1065\n",
      "[[1. 0.]] 3749 2045\n",
      "[[1. 0.]] 9495 4008\n",
      "[[1. 0.]] 100 9495\n",
      "[[1. 0.]] 4008 4207\n",
      "[[1. 0.]] 2690 3627\n",
      "[[1. 0.]] 1736 3029\n",
      "[[1. 0.]] 2045 2156\n",
      "[[1. 0.]] 1065 6154\n",
      "[[1. 0.]] 2298 3029\n",
      "[[1. 0.]] 2803 3054\n",
      "[[1. 0.]] 3749 2409\n",
      "[[1. 0.]] 2803 2298\n",
      "[[1. 0.]] 2156 9495\n",
      "[[1. 0.]] 4207 1736\n",
      "[[1. 0.]] 3054 2690\n",
      "[[1. 0.]] 2409 100\n",
      "[[1. 0.]] 3627 2020\n",
      "[[1. 0.]] 100 2045\n",
      "[[1. 0.]] 3029 1065\n",
      "[[1. 0.]] 3029 3749\n",
      "[[1. 0.]] 4008 6154\n",
      "[[1. 0.]] 9495 4207\n",
      "[[1. 0.]] 6154 2803\n",
      "[[1. 0.]] 2156 3029\n",
      "[[1. 0.]] 2690 2020\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 1736 3054\n",
      "[[1. 0.]] 2045 3627\n",
      "[[1. 0.]] 2298 2409\n",
      "[[1. 0.]] 3749 3029\n",
      "[[1. 0.]] 1065 4008\n",
      "[[1. 0.]] 4008 2156\n",
      "[[1. 0.]] 3627 6154\n",
      "[[1. 0.]] 3029 2045\n",
      "[[1. 0.]] 4207 100\n",
      "[[1. 0.]] 2803 2690\n",
      "[[1. 0.]] 3054 2298\n",
      "[[1. 0.]] 2020 1736\n",
      "[[1. 0.]] 3029 1065\n",
      "[[1. 0.]] 100 3749\n",
      "[[1. 0.]] 2298 2020\n",
      "[[1. 0.]] 2156 3627\n",
      "[[1. 0.]] 2690 4008\n",
      "[[1. 0.]] 6154 4207\n",
      "[[1. 0.]] 3749 2803\n",
      "[[1. 0.]] 1065 2409\n",
      "[[1. 0.]] 100 3029\n",
      "[[1. 0.]] 1736 100\n",
      "[[1. 0.]] 9495 3029\n",
      "[[1. 0.]] 4207 2156\n",
      "[[1. 0.]] 2020 6154\n",
      "[[1. 0.]] 3029 9495\n",
      "[[1. 0.]] 100 2690\n",
      "[[1. 0.]] 2803 1736\n",
      "[[1. 0.]] 2409 2045\n",
      "[[1. 0.]] 3627 1065\n",
      "[[1. 0.]] 3054 3749\n",
      "[[1. 0.]] 3029 100\n",
      "[[1. 0.]] 4008 2298\n",
      "[[1. 0.]] 4207 3029\n",
      "[[1. 0.]] 1736 4008\n",
      "[[1. 0.]] 1065 3054\n",
      "[[1. 0.]] 2156 2803\n",
      "[[1. 0.]] 2690 2409\n",
      "[[1. 0.]] 2020 3029\n",
      "[[1. 0.]] 2045 100\n",
      "[[1. 0.]] 2298 3627\n",
      "[[1. 0.]] 6154 100\n",
      "[[1. 0.]] 3749 9495\n",
      "[[1. 0.]] 3029 2156\n",
      "[[1. 0.]] 9495 2045\n",
      "[[1. 0.]] 100 2298\n",
      "[[1. 0.]] 4008 2020\n",
      "[[1. 0.]] 2803 1065\n",
      "[[1. 0.]] 3054 6154\n",
      "[[1. 0.]] 3029 2690\n",
      "[[1. 0.]] 2409 4207\n",
      "[[1. 0.]] 100 1736\n",
      "[[1. 0.]] 3627 3749\n",
      "[[1. 0.]] 100 4008\n",
      "[[1. 0.]] 2298 6154\n",
      "[[1. 0.]] 1065 2156\n",
      "[[1. 0.]] 2690 2803\n",
      "[[1. 0.]] 2020 3054\n",
      "[[1. 0.]] 1736 3627\n",
      "[[1. 0.]] 2045 3029\n",
      "[[1. 0.]] 3749 3029\n",
      "[[1. 0.]] 100 4207\n",
      "[[1. 0.]] 9495 2409\n",
      "[[1. 0.]] 2020 100\n",
      "[[1. 0.]] 2045 3054\n",
      "[[1. 0.]] 2409 9495\n",
      "[[1. 0.]] 2803 100\n",
      "[[1. 0.]] 4008 2690\n",
      "[[1. 0.]] 3029 100\n",
      "[[1. 0.]] 3749 2020\n",
      "[[1. 0.]] 2156 2045\n",
      "[[1. 0.]] 3054 1736\n",
      "[[1. 0.]] 2409 3627\n",
      "[[1. 0.]] 6154 1065\n",
      "[[1. 0.]] 3029 2298\n",
      "[[1. 0.]] 4207 9495\n",
      "[[1. 0.]] 100 3029\n",
      "[[1. 0.]] 9495 3029\n",
      "[[1. 0.]] 2690 3054\n",
      "[[1. 0.]] 100 2156\n",
      "[[1. 0.]] 2020 2409\n",
      "[[1. 0.]] 3627 4207\n",
      "[[1. 0.]] 2045 1065\n",
      "[[1. 0.]] 2803 6154\n",
      "[[1. 0.]] 1736 3749\n",
      "[[1. 0.]] 2298 4008\n",
      "[[1. 0.]] 4207 100\n",
      "[[1. 0.]] 2409 2690\n",
      "[[1. 0.]] 3029 9495\n",
      "[[1. 0.]] 3029 1736\n",
      "[[1. 0.]] 6154 2045\n",
      "[[1. 0.]] 1065 3627\n",
      "[[1. 0.]] 2156 2298\n",
      "[[1. 0.]] 3054 2803\n",
      "[[1. 0.]] 2020 100\n",
      "[[1. 0.]] 3749 4008\n",
      "[[1. 0.]] 2690 4207\n",
      "[[1. 0.]] 4008 1065\n",
      "[[1. 0.]] 100 2156\n",
      "[[1. 0.]] 2803 2020\n",
      "[[1. 0.]] 100 3029\n",
      "[[1. 0.]] 1736 2298\n",
      "[[1. 0.]] 2045 2409\n",
      "[[1. 0.]] 3029 3749\n",
      "[[1. 0.]] 3627 3054\n",
      "[[1. 0.]] 9495 6154\n",
      "[[1. 0.]] 2409 3029\n",
      "[[1. 0.]] 2045 9495\n",
      "[[1. 0.]] 2298 100\n",
      "[[1. 0.]] 1065 2803\n",
      "[[1. 0.]] 3029 1736\n",
      "[[1. 0.]] 2020 2690\n",
      "[[1. 0.]] 6154 3627\n",
      "[[1. 0.]] 2156 3749\n",
      "[[1. 0.]] 3054 100\n",
      "[[1. 0.]] 4207 4008\n",
      "[[1. 0.]] 2803 2156\n",
      "[[1. 0.]] 1736 6154\n",
      "[[1. 0.]] 4008 3029\n",
      "[[1. 0.]] 4207 1065\n",
      "[[1. 0.]] 2690 3029\n",
      "[[1. 0.]] 100 2409\n",
      "[[1. 0.]] 3627 2045\n",
      "[[1. 0.]] 3749 3054\n",
      "[[1. 0.]] 100 2020\n",
      "[[1. 0.]] 9495 2298\n",
      "[[1. 0.]] 2020 4008\n",
      "[[1. 0.]] 9495 100\n",
      "[[1. 0.]] 3029 3627\n",
      "[[1. 0.]] 1065 100\n",
      "[[1. 0.]] 2156 2690\n",
      "[[1. 0.]] 2409 3054\n",
      "[[1. 0.]] 2045 1736\n",
      "[[1. 0.]] 3029 4207\n",
      "[[1. 0.]] 2298 2803\n",
      "[[1. 0.]] 6154 3749\n",
      "[[1. 0.]] 4008 2045\n",
      "[[1. 0.]] 2803 2409\n",
      "[[1. 0.]] 3054 2156\n",
      "[[1. 0.]] 2690 3029\n",
      "[[1. 0.]] 100 1065\n",
      "[[1. 0.]] 1736 2020\n",
      "[[1. 0.]] 3749 2298\n",
      "[[1. 0.]] 100 3029\n",
      "[[1. 0.]] 4207 6154\n",
      "[[1. 0.]] 14695 1880\n",
      "[[1. 0.]] 2705 10390\n",
      "[[1. 0.]] 3781 2956\n",
      "[[1. 0.]] 4146 3982\n",
      "[[1. 0.]] 2817 2512\n",
      "[[1. 0.]] 2482 3883\n",
      "[[1. 0.]] 6821 1553\n",
      "[[1. 0.]] 5188 7311\n",
      "[[1. 0.]] 3890 7938\n",
      "[[1. 0.]] 7151 8832\n",
      "[[1. 0.]] 7938 3781\n",
      "[[1. 0.]] 1553 2482\n",
      "[[1. 0.]] 3982 2817\n",
      "[[1. 0.]] 1880 3890\n",
      "[[1. 0.]] 2956 14695\n",
      "[[1. 0.]] 2512 2705\n",
      "[[1. 0.]] 10390 6821\n",
      "[[1. 0.]] 3883 4146\n",
      "[[1. 0.]] 8832 5188\n",
      "[[1. 0.]] 7311 7151\n",
      "[[1. 0.]] 1553 3982\n",
      "[[1. 0.]] 1880 8832\n",
      "[[1. 0.]] 7151 4146\n",
      "[[1. 0.]] 3883 5188\n",
      "[[1. 0.]] 2512 2956\n",
      "[[1. 0.]] 2817 2705\n",
      "[[1. 0.]] 14695 7938\n",
      "[[1. 0.]] 2482 10390\n",
      "[[1. 0.]] 7311 3781\n",
      "[[1. 0.]] 6821 3890\n",
      "[[1. 0.]] 2956 7151\n",
      "[[1. 0.]] 10390 2512\n",
      "[[1. 0.]] 3890 2817\n",
      "[[1. 0.]] 8832 3883\n",
      "[[1. 0.]] 5188 2482\n",
      "[[1. 0.]] 2705 1880\n",
      "[[1. 0.]] 4146 1553\n",
      "[[1. 0.]] 3781 14695\n",
      "[[1. 0.]] 3982 7311\n",
      "[[1. 0.]] 7938 6821\n",
      "[[1. 0.]] 14695 3890\n",
      "[[1. 0.]] 7311 8832\n",
      "[[1. 0.]] 6821 4146\n",
      "[[1. 0.]] 7151 5188\n",
      "[[1. 0.]] 3883 2956\n",
      "[[1. 0.]] 2512 3781\n",
      "[[1. 0.]] 1880 10390\n",
      "[[1. 0.]] 2482 3982\n",
      "[[1. 0.]] 2817 7938\n",
      "[[1. 0.]] 1553 2705\n",
      "[[1. 0.]] 2956 2482\n",
      "[[1. 0.]] 5188 6821\n",
      "[[1. 0.]] 10390 2817\n",
      "[[1. 0.]] 3982 3883\n",
      "[[1. 0.]] 3781 1880\n",
      "[[1. 0.]] 3890 2512\n",
      "[[1. 0.]] 2705 7151\n",
      "[[1. 0.]] 4146 7311\n",
      "[[1. 0.]] 7938 1553\n",
      "[[1. 0.]] 8832 14695\n",
      "[[1. 0.]] 3883 14695\n",
      "[[1. 0.]] 7311 2817\n",
      "[[1. 0.]] 1553 3781\n",
      "[[1. 0.]] 8832 2512\n",
      "[[1. 0.]] 6821 2956\n",
      "[[1. 0.]] 4146 1880\n",
      "[[1. 0.]] 2482 2705\n",
      "[[1. 0.]] 3982 10390\n",
      "[[1. 0.]] 5188 3890\n",
      "[[1. 0.]] 7151 7938\n",
      "[[1. 0.]] 2512 6821\n",
      "[[1. 0.]] 14695 5188\n",
      "[[1. 0.]] 1880 1553\n",
      "[[1. 0.]] 3781 3982\n",
      "[[1. 0.]] 2817 3883\n",
      "[[1. 0.]] 2705 4146\n",
      "[[1. 0.]] 10390 7311\n",
      "[[1. 0.]] 7938 2482\n",
      "[[1. 0.]] 2956 8832\n",
      "[[1. 0.]] 3890 7151\n",
      "[[1. 0.]] 3982 2705\n",
      "[[1. 0.]] 7311 2956\n",
      "[[1. 0.]] 1553 2512\n",
      "[[1. 0.]] 8832 3890\n",
      "[[1. 0.]] 6821 2817\n",
      "[[1. 0.]] 5188 3781\n",
      "[[1. 0.]] 2482 1880\n",
      "[[1. 0.]] 4146 10390\n",
      "[[1. 0.]] 7151 14695\n",
      "[[1. 0.]] 3883 7938\n",
      "[[1. 0.]] 2956 5188\n",
      "[[1. 0.]] 10390 1553\n",
      "[[1. 0.]] 2705 3883\n",
      "[[1. 0.]] 2512 3982\n",
      "[[1. 0.]] 2817 2482\n",
      "[[1. 0.]] 3781 8832\n",
      "[[1. 0.]] 3890 7311\n",
      "[[1. 0.]] 14695 6821\n",
      "[[1. 0.]] 7938 4146\n",
      "[[1. 0.]] 1880 7151\n",
      "[[1. 0.]] 2482 7151\n",
      "[[1. 0.]] 2512 1880\n",
      "[[1. 0.]] 1553 14695\n",
      "[[1. 0.]] 10390 2956\n",
      "[[1. 0.]] 7938 7311\n",
      "[[1. 0.]] 3883 3781\n",
      "[[1. 0.]] 2705 3890\n",
      "[[1. 0.]] 2817 8832\n",
      "[[1. 0.]] 4146 5188\n",
      "[[1. 0.]] 3982 6821\n",
      "[[1. 0.]] 1880 2817\n",
      "[[1. 0.]] 8832 4146\n",
      "[[1. 0.]] 3890 2482\n",
      "[[1. 0.]] 6821 3883\n",
      "[[1. 0.]] 3781 2705\n",
      "[[1. 0.]] 2956 3982\n",
      "[[1. 0.]] 5188 7938\n",
      "[[1. 0.]] 7311 1553\n",
      "[[1. 0.]] 7151 2512\n",
      "[[1. 0.]] 14695 10390\n",
      "[[1. 0.]] 2705 6821\n",
      "[[1. 0.]] 7938 2956\n",
      "[[1. 0.]] 3982 1880\n",
      "[[1. 0.]] 4146 14695\n",
      "[[1. 0.]] 2512 5188\n",
      "[[1. 0.]] 2817 3781\n",
      "[[1. 0.]] 2482 7311\n",
      "[[1. 0.]] 10390 8832\n",
      "[[1. 0.]] 3883 7151\n",
      "[[1. 0.]] 1553 3890\n",
      "[[1. 0.]] 3890 10390\n",
      "[[1. 0.]] 14695 2512\n",
      "[[1. 0.]] 8832 2705\n",
      "[[1. 0.]] 6821 2482\n",
      "[[1. 0.]] 3781 4146\n",
      "[[1. 0.]] 2956 2817\n",
      "[[1. 0.]] 7311 3883\n",
      "[[1. 0.]] 1880 7938\n",
      "[[1. 0.]] 7151 1553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]] 5188 3982\n",
      "[[1. 0.]] 4146 2482\n",
      "[[1. 0.]] 3781 10390\n",
      "[[1. 0.]] 7311 2705\n",
      "[[1. 0.]] 7151 6821\n",
      "[[1. 0.]] 5188 2817\n",
      "[[1. 0.]] 8832 1553\n",
      "[[1. 0.]] 2956 1880\n",
      "[[1. 0.]] 14695 3982\n",
      "[[1. 0.]] 3883 3890\n",
      "[[1. 0.]] 7938 2512\n",
      "[[1. 0.]] 3982 8832\n",
      "[[1. 0.]] 6821 3781\n",
      "[[1. 0.]] 2817 4146\n",
      "[[1. 0.]] 2482 14695\n",
      "[[1. 0.]] 10390 7151\n",
      "[[1. 0.]] 1553 5188\n",
      "[[1. 0.]] 3890 2956\n",
      "[[1. 0.]] 1880 3883\n",
      "[[1. 0.]] 2512 7311\n",
      "[[1. 0.]] 2705 7938\n",
      "[[1. 0.]] 14695 2817\n",
      "[[1. 0.]] 8832 2482\n",
      "[[1. 0.]] 3883 1553\n",
      "[[1. 0.]] 5188 1880\n",
      "[[1. 0.]] 3781 3890\n",
      "[[1. 0.]] 2956 2705\n",
      "[[1. 0.]] 7311 6821\n",
      "[[1. 0.]] 7151 3982\n",
      "[[1. 0.]] 7938 10390\n",
      "[[1. 0.]] 4146 2512\n",
      "[[1. 0.]] 3982 7938\n",
      "[[1. 0.]] 1553 2956\n",
      "[[1. 0.]] 3890 4146\n",
      "[[1. 0.]] 1880 7311\n",
      "[[1. 0.]] 2512 3883\n",
      "[[1. 0.]] 2482 3781\n",
      "[[1. 0.]] 10390 5188\n",
      "[[1. 0.]] 2817 7151\n",
      "[[1. 0.]] 6821 8832\n",
      "[[1. 0.]] 6821 2512\n",
      "[[1. 0.]] 1553 1880\n",
      "[[1. 0.]] 8832 2956\n",
      "[[1. 0.]] 3982 3781\n",
      "[[1. 0.]] 3883 2817\n",
      "[[1. 0.]] 4146 2705\n",
      "[[1. 0.]] 2482 7938\n",
      "[[1. 0.]] 7151 3890\n",
      "[[1. 0.]] 5188 14695\n",
      "[[1. 0.]] 7311 10390\n",
      "[[1. 0.]] 2512 2482\n",
      "[[1. 0.]] 3890 3982\n",
      "[[1. 0.]] 2956 4146\n",
      "[[1. 0.]] 2817 1553\n",
      "[[1. 0.]] 1880 6821\n",
      "[[1. 0.]] 2705 5188\n",
      "[[1. 0.]] 3781 7151\n",
      "[[1. 0.]] 7938 8832\n",
      "[[1. 0.]] 14695 7311\n",
      "[[1. 0.]] 10390 3883\n",
      "[[1. 0.]] 3781 1553\n",
      "[[1. 0.]] 2512 8832\n",
      "[[1. 0.]] 3890 5188\n",
      "[[1. 0.]] 2956 6821\n",
      "[[1. 0.]] 2817 7311\n",
      "[[1. 0.]] 10390 3982\n",
      "[[1. 0.]] 1880 4146\n",
      "[[1. 0.]] 2705 2482\n",
      "[[1. 0.]] 7938 7151\n",
      "[[1. 0.]] 14695 3883\n",
      "[[1. 0.]] 3883 2705\n",
      "[[1. 0.]] 4146 7938\n",
      "[[1. 0.]] 7311 3890\n",
      "[[1. 0.]] 8832 3781\n",
      "[[1. 0.]] 3982 2512\n",
      "[[1. 0.]] 7151 1880\n",
      "[[1. 0.]] 5188 2956\n",
      "[[1. 0.]] 6821 14695\n",
      "[[1. 0.]] 2482 2817\n",
      "[[1. 0.]] 1553 10390\n",
      "[[1. 0.]] 2817 6821\n",
      "[[1. 0.]] 10390 4146\n",
      "[[1. 0.]] 7938 3883\n",
      "[[1. 0.]] 1880 2482\n",
      "[[1. 0.]] 2705 3982\n",
      "[[1. 0.]] 2956 7311\n",
      "[[1. 0.]] 2512 1553\n",
      "[[1. 0.]] 3890 8832\n",
      "[[1. 0.]] 3781 5188\n",
      "[[1. 0.]] 14695 7151\n",
      "[[1. 0.]] 1553 2817\n",
      "[[1. 0.]] 3982 3890\n",
      "[[1. 0.]] 3883 10390\n",
      "[[1. 0.]] 2482 2512\n",
      "[[1. 0.]] 4146 2956\n",
      "[[1. 0.]] 8832 7938\n",
      "[[1. 0.]] 5188 2705\n",
      "[[1. 0.]] 6821 1880\n",
      "[[1. 0.]] 7151 3781\n",
      "[[1. 0.]] 7311 14695\n",
      "[[1. 0.]] 2705 14695\n",
      "[[1. 0.]] 5188 8832\n",
      "[[1. 0.]] 14695 2956\n",
      "[[1. 0.]] 3890 1880\n",
      "[[1. 0.]] 2705 2512\n",
      "[[1. 0.]] 4146 3883\n",
      "[[1. 0.]] 2817 3982\n",
      "[[1. 0.]] 2482 1553\n",
      "[[1. 0.]] 7151 7311\n",
      "[[1. 0.]] 3781 7938\n",
      "[[1. 0.]] 6821 10390\n",
      "[[1. 0.]] 3982 4146\n",
      "[[1. 0.]] 2512 2817\n",
      "[[1. 0.]] 3883 2482\n",
      "[[1. 0.]] 7311 5188\n",
      "[[1. 0.]] 2956 3781\n",
      "[[1. 0.]] 1880 14695\n",
      "[[1. 0.]] 1553 6821\n",
      "[[1. 0.]] 7938 3890\n",
      "[[1. 0.]] 8832 7151\n",
      "[[1. 0.]] 10390 2705\n",
      "[[1. 0.]] 8832 6821\n",
      "[[1. 0.]] 3883 2512\n",
      "[[1. 0.]] 3781 2482\n",
      "[[1. 0.]] 2956 1553\n",
      "[[1. 0.]] 4146 3890\n",
      "[[1. 0.]] 5188 10390\n",
      "[[1. 0.]] 7311 1880\n",
      "[[1. 0.]] 7151 2817\n",
      "[[1. 0.]] 7938 3982\n",
      "[[1. 0.]] 14695 2705\n",
      "[[1. 0.]] 1880 5188\n",
      "[[1. 0.]] 2512 4146\n",
      "[[1. 0.]] 3890 3781\n",
      "[[1. 0.]] 2705 2956\n",
      "[[1. 0.]] 2482 8832\n",
      "[[1. 0.]] 2817 14695\n",
      "[[1. 0.]] 6821 7311\n",
      "[[1. 0.]] 3982 7151\n",
      "[[1. 0.]] 14695 2482\n",
      "[[1. 0.]] 7311 2512\n",
      "[[1. 0.]] 7938 2705\n",
      "[[1. 0.]] 3883 1880\n",
      "[[1. 0.]] 2956 3890\n",
      "[[1. 0.]] 4146 2817\n",
      "[[1. 0.]] 3781 6821\n",
      "[[1. 0.]] 8832 3982\n",
      "[[1. 0.]] 7151 10390\n",
      "[[1. 0.]] 5188 1553\n",
      "[[1. 0.]] 6139 13105\n",
      "[[1. 0.]] 4059 8949\n",
      "[[1. 0.]] 9770 7427\n",
      "[[1. 0.]] 2475 3861\n",
      "[[1. 0.]] 5396 4803\n",
      "[[1. 0.]] 100 3267\n",
      "[[1. 0.]] 3663 4554\n",
      "[[1. 0.]] 6273 7447\n",
      "[[1. 0.]] 4257 4059\n",
      "[[1. 0.]] 9329 7881\n",
      "[[1. 0.]] 4803 7447\n",
      "[[1. 0.]] 4554 5396\n",
      "[[1. 0.]] 3267 3861\n",
      "[[1. 0.]] 8949 4059\n",
      "[[1. 0.]] 7881 6139\n",
      "[[1. 0.]] 4059 9770\n",
      "[[1. 0.]] 2475 7427\n",
      "[[1. 0.]] 3663 6273\n",
      "[[1. 0.]] 100 9329\n",
      "[[1. 0.]] 13105 4257\n",
      "[[1. 0.]] 7447 4059\n",
      "[[1. 0.]] 6139 7427\n",
      "[[1. 0.]] 3267 13105\n",
      "[[1. 0.]] 4554 4059\n",
      "[[1. 0.]] 7881 3663\n",
      "[[1. 0.]] 4257 100\n",
      "[[1. 0.]] 9770 2475\n",
      "[[1. 0.]] 9329 3861\n",
      "[[1. 0.]] 6273 4803\n",
      "[[1. 0.]] 5396 8949\n",
      "[[1. 0.]] 2475 6139\n",
      "[[1. 0.]] 8949 4554\n",
      "[[1. 0.]] 100 5396\n",
      "[[1. 0.]] 7427 9329\n",
      "[[1. 0.]] 13105 9770\n",
      "[[1. 0.]] 3861 6273\n",
      "[[1. 0.]] 3663 7447\n",
      "[[1. 0.]] 4059 4803\n",
      "[[1. 0.]] 4059 3267\n",
      "[[1. 0.]] 4257 7881\n",
      "[[1. 0.]] 3267 4257\n",
      "[[1. 0.]] 5396 4059\n",
      "[[1. 0.]] 4554 3861\n",
      "[[1. 0.]] 9329 4059\n",
      "[[1. 0.]] 4803 13105\n",
      "[[1. 0.]] 7881 2475\n",
      "[[1. 0.]] 6273 7427\n",
      "[[1. 0.]] 9770 100\n",
      "[[1. 0.]] 6139 3663\n",
      "[[1. 0.]] 7447 8949\n",
      "[[1. 0.]] 4059 4803\n",
      "[[1. 0.]] 4257 4554\n",
      "[[1. 0.]] 13105 5396\n",
      "[[1. 0.]] 2475 9329\n",
      "[[1. 0.]] 100 6139\n",
      "[[1. 0.]] 9770 7881\n",
      "[[1. 0.]] 8949 3267\n",
      "[[1. 0.]] 3861 7447\n",
      "[[1. 0.]] 4059 6273\n",
      "[[1. 0.]] 7427 3663\n",
      "[[1. 0.]] 5396 4257\n",
      "[[1. 0.]] 6139 9770\n",
      "[[1. 0.]] 7881 13105\n",
      "[[1. 0.]] 4803 100\n",
      "[[1. 0.]] 9329 8949\n",
      "[[1. 0.]] 6273 4059\n",
      "[[1. 0.]] 3861 4059\n",
      "[[1. 0.]] 3663 2475\n",
      "[[1. 0.]] 4554 3267\n",
      "[[1. 0.]] 7447 7427\n",
      "[[1. 0.]] 4257 3861\n",
      "[[1. 0.]] 100 4554\n",
      "[[1. 0.]] 8949 4803\n",
      "[[1. 0.]] 9770 3663\n",
      "[[1. 0.]] 3267 5396\n",
      "[[1. 0.]] 2475 6273\n",
      "[[1. 0.]] 4059 6139\n",
      "[[1. 0.]] 4059 9329\n",
      "[[1. 0.]] 7427 7881\n",
      "[[1. 0.]] 13105 7447\n",
      "[[1. 0.]] 4803 3267\n",
      "[[1. 0.]] 3861 13105\n",
      "[[1. 0.]] 9329 9770\n",
      "[[1. 0.]] 7881 100\n",
      "[[1. 0.]] 2475 8949\n",
      "[[1. 0.]] 3663 4059\n",
      "[[1. 0.]] 7427 4257\n",
      "[[1. 0.]] 6273 5396\n",
      "[[1. 0.]] 6139 4059\n",
      "[[1. 0.]] 7447 4554\n",
      "[[1. 0.]] 5396 3663\n",
      "[[1. 0.]] 100 2475\n",
      "[[1. 0.]] 4059 3861\n",
      "[[1. 0.]] 9329 6139\n",
      "[[1. 0.]] 4059 7427\n",
      "[[1. 0.]] 4803 4257\n",
      "[[1. 0.]] 4554 6273\n",
      "[[1. 0.]] 7447 7881\n",
      "[[1. 0.]] 3267 9770\n",
      "[[1. 0.]] 3663 9329\n",
      "[[1. 0.]] 13105 4059\n",
      "[[1. 0.]] 9770 7447\n",
      "[[1. 0.]] 7427 4554\n",
      "[[1. 0.]] 6139 6273\n",
      "[[1. 0.]] 4257 4059\n",
      "[[1. 0.]] 8949 100\n",
      "[[1. 0.]] 2475 3267\n",
      "[[1. 0.]] 3861 5396\n",
      "[[1. 0.]] 7881 4803\n",
      "[[1. 0.]] 6273 9770\n",
      "[[1. 0.]] 4554 13105\n",
      "[[1. 0.]] 7447 9329\n",
      "[[1. 0.]] 8949 4257\n",
      "[[1. 0.]] 4059 2475\n",
      "[[1. 0.]] 5396 6139\n",
      "[[1. 0.]] 3267 3663\n",
      "[[1. 0.]] 4059 7881\n",
      "[[1. 0.]] 100 3861\n",
      "[[1. 0.]] 4803 7427\n",
      "[[1. 0.]] 7427 100\n",
      "[[1. 0.]] 3663 4059\n",
      "[[1. 0.]] 9770 4803\n",
      "[[1. 0.]] 3861 8949\n",
      "[[1. 0.]] 13105 4059\n",
      "[[1. 0.]] 2475 5396\n",
      "[[1. 0.]] 6139 4554\n",
      "[[1. 0.]] 9329 6273\n",
      "[[1. 0.]] 7881 3267\n",
      "[[1. 0.]] 4257 7447\n",
      "[[1. 0.]] 4554 2475\n",
      "[[1. 0.]] 100 13105\n",
      "[[1. 0.]] 4257 9770\n",
      "[[1. 0.]] 4803 9329\n",
      "[[1. 0.]] 8949 7427\n",
      "[[1. 0.]] 6273 7881\n",
      "[[1. 0.]] 3267 6139\n",
      "[[1. 0.]] 3861 3663\n",
      "[[1. 0.]] 5396 4059\n",
      "[[1. 0.]] 4059 7447\n",
      "[[1. 0.]] 4059 4059\n",
      "[[1. 0.]] 3663 8949\n",
      "[[1. 0.]] 7427 3861\n",
      "[[1. 0.]] 2475 4257\n",
      "[[1. 0.]] 9770 5396\n",
      "[[1. 0.]] 7447 100\n",
      "[[1. 0.]] 6139 4803\n",
      "[[1. 0.]] 6273 3267\n",
      "[[1. 0.]] 7881 4554\n",
      "[[1. 0.]] 9329 13105\n",
      "[[1. 0.]] 5396 9329\n",
      "[[1. 0.]] 8949 6273\n",
      "[[1. 0.]] 4803 3663\n",
      "[[1. 0.]] 4554 9770\n",
      "[[1. 0.]] 13105 2475\n",
      "[[1. 0.]] 3861 7881\n",
      "[[1. 0.]] 4257 6139\n",
      "[[1. 0.]] 4059 7427\n",
      "[[1. 0.]] 100 4059\n",
      "[[1. 0.]] 3267 7447\n",
      "[[1. 0.]] 3663 100\n",
      "[[1. 0.]] 4803 4554\n",
      "[[1. 0.]] 7427 13105\n",
      "[[1. 0.]] 6139 3861\n",
      "[[1. 0.]] 9329 3267\n",
      "[[1. 0.]] 7881 4059\n",
      "[[1. 0.]] 4059 2475\n",
      "[[1. 0.]] 6273 4257\n",
      "[[1. 0.]] 7447 5396\n",
      "[[1. 0.]] 9770 8949\n",
      "[[1. 0.]] 13105 8949\n",
      "[[1. 0.]] 3861 4803\n",
      "[[1. 0.]] 2475 7447\n",
      "[[1. 0.]] 13105 3663\n",
      "[[1. 0.]] 5396 7881\n",
      "[[1. 0.]] 4059 9770\n",
      "[[1. 0.]] 100 6273\n",
      "[[1. 0.]] 3267 7427\n",
      "[[1. 0.]] 4257 9329\n",
      "[[1. 0.]] 4554 4059\n",
      "[[1. 0.]] 8949 6139\n",
      "[[1. 0.]] 4059 100\n",
      "[[1. 0.]] 7447 6139\n",
      "[[1. 0.]] 9770 3861\n",
      "[[1. 0.]] 7881 8949\n",
      "[[1. 0.]] 9329 4554\n",
      "[[1. 0.]] 6273 13105\n",
      "[[1. 0.]] 4803 2475\n",
      "[[1. 0.]] 7427 5396\n",
      "[[1. 0.]] 3663 4257\n",
      "[[1. 0.]] 4059 3267\n",
      "[[1. 0.]] 100 7881\n",
      "[[1. 0.]] 4554 3663\n",
      "[[1. 0.]] 8949 7447\n",
      "[[1. 0.]] 3267 4059\n",
      "[[1. 0.]] 3861 9329\n",
      "[[1. 0.]] 2475 9770\n",
      "[[1. 0.]] 4257 7427\n",
      "[[1. 0.]] 5396 6273\n",
      "[[1. 0.]] 6139 4059\n",
      "[[1. 0.]] 13105 4803\n",
      "[[1. 0.]] 3267 4554\n",
      "[[1. 0.]] 6273 6139\n",
      "[[1. 0.]] 9770 13105\n",
      "[[1. 0.]] 3663 5396\n",
      "[[1. 0.]] 7447 4803\n",
      "[[1. 0.]] 9329 100\n",
      "[[1. 0.]] 4059 3861\n",
      "[[1. 0.]] 7881 4257\n",
      "[[1. 0.]] 7427 2475\n",
      "[[1. 0.]] 4059 8949\n",
      "[[1. 0.]] 4803 6273\n",
      "[[1. 0.]] 8949 9329\n",
      "[[1. 0.]] 2475 4059\n",
      "[[1. 0.]] 9770 4059\n",
      "[[1. 0.]] 100 7427\n",
      "[[1. 0.]] 3861 4257\n",
      "[[1. 0.]] 6139 7881\n",
      "[[1. 0.]] 7447 3663\n",
      "[[1. 0.]] 5396 3267\n",
      "[[1. 0.]] 13105 4554\n",
      "[[1. 0.]] 3663 3861\n",
      "[[1. 0.]] 4554 100\n",
      "[[1. 0.]] 7881 9770\n",
      "[[1. 0.]] 4059 5396\n",
      "[[1. 0.]] 9329 4803\n",
      "[[1. 0.]] 6273 2475\n",
      "[[1. 0.]] 7427 6139\n",
      "[[1. 0.]] 3267 8949\n",
      "[[1. 0.]] 4059 7447\n",
      "[[1. 0.]] 4257 13105\n",
      "[[1. 0.]] 9770 9329\n",
      "[[1. 0.]] 2475 3663\n",
      "[[1. 0.]] 13105 7881\n",
      "[[1. 0.]] 5396 4554\n",
      "[[1. 0.]] 4803 4059\n",
      "[[1. 0.]] 7447 6273\n",
      "[[1. 0.]] 100 4257\n",
      "[[1. 0.]] 6139 3267\n",
      "[[1. 0.]] 8949 4059\n",
      "[[1. 0.]] 4257 2475\n",
      "[[1. 0.]] 4059 100\n",
      "[[1. 0.]] 13105 3861\n",
      "[[1. 0.]] 7427 9770\n",
      "[[1. 0.]] 4554 8949\n",
      "[[1. 0.]] 3267 4803\n",
      "[[1. 0.]] 3663 6139\n",
      "[[1. 0.]] 4059 6273\n",
      "[[1. 0.]] 7881 7447\n",
      "[[1. 0.]] 9329 5396\n",
      "[[1. 0.]] 7427 4059\n",
      "[[1. 0.]] 3861 4554\n",
      "[[1. 0.]] 9770 4257\n",
      "[[1. 0.]] 100 3663\n",
      "[[1. 0.]] 4803 4059\n",
      "[[1. 0.]] 7447 3267\n",
      "[[1. 0.]] 6139 5396\n",
      "[[1. 0.]] 6273 9329\n",
      "[[1. 0.]] 2475 7881\n",
      "[[1. 0.]] 8949 13105\n",
      "[[1. 0.]] 3663 9770\n",
      "[[1. 0.]] 3861 2475\n",
      "[[1. 0.]] 9329 7447\n",
      "[[1. 0.]] 13105 7427\n",
      "[[1. 0.]] 7881 4059\n",
      "[[1. 0.]] 3267 6273\n",
      "[[1. 0.]] 4059 6139\n",
      "[[1. 0.]] 4554 4803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]] 5396 100\n",
      "[[1. 0.]] 4257 8949\n",
      "[[1. 0.]] 3861 7427\n",
      "[[1. 0.]] 100 9319\n",
      "[[1. 0.]] 2679 100\n",
      "[[1. 0.]] 3100 4490\n",
      "[[1. 0.]] 6735 1932\n",
      "[[1. 0.]] 2588 6846\n",
      "[[1. 0.]] 2866 1140\n",
      "[[1. 0.]] 3817 3086\n",
      "[[1. 0.]] 2280 100\n",
      "[[1. 0.]] 2242 7928\n",
      "[[1. 0.]] 9035 1781\n",
      "[[1. 0.]] 100 2242\n",
      "[[1. 0.]] 4490 1140\n",
      "[[1. 0.]] 9319 100\n",
      "[[1. 0.]] 6846 6735\n",
      "[[1. 0.]] 3100 100\n",
      "[[1. 0.]] 7928 3817\n",
      "[[1. 0.]] 2866 9035\n",
      "[[1. 0.]] 1932 2679\n",
      "[[1. 0.]] 3086 2588\n",
      "[[1. 0.]] 1781 2280\n",
      "[[1. 0.]] 2679 9319\n",
      "[[1. 0.]] 100 2588\n",
      "[[1. 0.]] 9035 3100\n",
      "[[1. 0.]] 1932 7928\n",
      "[[1. 0.]] 100 2866\n",
      "[[1. 0.]] 1140 100\n",
      "[[1. 0.]] 2242 6846\n",
      "[[1. 0.]] 6735 3086\n",
      "[[1. 0.]] 2280 4490\n",
      "[[1. 0.]] 3817 1781\n",
      "[[1. 0.]] 2866 1932\n",
      "[[1. 0.]] 3100 1140\n",
      "[[1. 0.]] 9319 2280\n",
      "[[1. 0.]] 4490 9035\n",
      "[[1. 0.]] 3086 2242\n",
      "[[1. 0.]] 2588 3817\n",
      "[[1. 0.]] 100 6735\n",
      "[[1. 0.]] 1781 100\n",
      "[[1. 0.]] 7928 2679\n",
      "[[1. 0.]] 6846 100\n",
      "[[1. 0.]] 2280 3100\n",
      "[[1. 0.]] 1140 9319\n",
      "[[1. 0.]] 6735 7928\n",
      "[[1. 0.]] 100 2866\n",
      "[[1. 0.]] 9035 6846\n",
      "[[1. 0.]] 2679 2588\n",
      "[[1. 0.]] 100 3086\n",
      "[[1. 0.]] 1932 100\n",
      "[[1. 0.]] 2242 1781\n",
      "[[1. 0.]] 3817 4490\n",
      "[[1. 0.]] 9319 2242\n",
      "[[1. 0.]] 2588 9035\n",
      "[[1. 0.]] 3086 7928\n",
      "[[1. 0.]] 100 1140\n",
      "[[1. 0.]] 6846 1932\n",
      "[[1. 0.]] 3100 100\n",
      "[[1. 0.]] 1781 6735\n",
      "[[1. 0.]] 2866 2280\n",
      "[[1. 0.]] 4490 2679\n",
      "[[1. 0.]] 100 3817\n",
      "[[1. 0.]] 2242 100\n",
      "[[1. 0.]] 2280 2588\n",
      "[[1. 0.]] 1932 4490\n",
      "[[1. 0.]] 2679 3100\n",
      "[[1. 0.]] 6735 2866\n",
      "[[1. 0.]] 7928 1781\n",
      "[[1. 0.]] 100 6846\n",
      "[[1. 0.]] 3817 100\n",
      "[[1. 0.]] 9035 9319\n",
      "[[1. 0.]] 6846 7928\n",
      "[[1. 0.]] 100 2280\n",
      "[[1. 0.]] 9319 100\n",
      "[[1. 0.]] 3086 9035\n",
      "[[1. 0.]] 3100 3817\n",
      "[[1. 0.]] 2588 6735\n",
      "[[1. 0.]] 2866 2242\n",
      "[[1. 0.]] 100 1932\n",
      "[[1. 0.]] 4490 1781\n",
      "[[1. 0.]] 1140 2679\n",
      "[[1. 0.]] 2280 3086\n",
      "[[1. 0.]] 1781 9319\n",
      "[[1. 0.]] 9035 100\n",
      "[[1. 0.]] 1932 1140\n",
      "[[1. 0.]] 100 2588\n",
      "[[1. 0.]] 7928 3100\n",
      "[[1. 0.]] 3817 2866\n",
      "[[1. 0.]] 2242 100\n",
      "[[1. 0.]] 6735 4490\n",
      "[[1. 0.]] 2679 6846\n",
      "[[1. 0.]] 100 2280\n",
      "[[1. 0.]] 1140 9035\n",
      "[[1. 0.]] 100 7928\n",
      "[[1. 0.]] 9319 1932\n",
      "[[1. 0.]] 6846 3817\n",
      "[[1. 0.]] 3100 6735\n",
      "[[1. 0.]] 2588 1781\n",
      "[[1. 0.]] 2866 100\n",
      "[[1. 0.]] 3086 2679\n",
      "[[1. 0.]] 4490 2242\n",
      "[[1. 0.]] 6735 100\n",
      "[[1. 0.]] 100 9035\n",
      "[[1. 0.]] 3817 9319\n",
      "[[1. 0.]] 7928 2866\n",
      "[[1. 0.]] 1932 3100\n",
      "[[1. 0.]] 2280 1140\n",
      "[[1. 0.]] 1781 3086\n",
      "[[1. 0.]] 2679 100\n",
      "[[1. 0.]] 4490 6846\n",
      "[[1. 0.]] 2242 2588\n",
      "[[1. 0.]] 3086 100\n",
      "[[1. 0.]] 1140 3817\n",
      "[[1. 0.]] 9035 2280\n",
      "[[1. 0.]] 100 1932\n",
      "[[1. 0.]] 2866 2679\n",
      "[[1. 0.]] 6846 1781\n",
      "[[1. 0.]] 3100 2242\n",
      "[[1. 0.]] 2588 7928\n",
      "[[1. 0.]] 100 6735\n",
      "[[1. 0.]] 9319 4490\n",
      "[[1. 0.]] 7928 9319\n",
      "[[1. 0.]] 4490 100\n",
      "[[1. 0.]] 3817 9035\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 6735 1140\n",
      "[[1. 0.]] 2280 2679\n",
      "[[1. 0.]] 3086 6846\n",
      "[[1. 0.]] 2588 3100\n",
      "[[1. 0.]] 1781 2866\n",
      "[[1. 0.]] 2242 1932\n",
      "[[1. 0.]] 1140 7928\n",
      "[[1. 0.]] 1932 3817\n",
      "[[1. 0.]] 2679 1781\n",
      "[[1. 0.]] 9319 3086\n",
      "[[1. 0.]] 9035 2242\n",
      "[[1. 0.]] 6846 3100\n",
      "[[1. 0.]] 100 4490\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 2280 6735\n",
      "[[1. 0.]] 2866 2588\n",
      "[[1. 0.]] 9035 6735\n",
      "[[1. 0.]] 7928 2280\n",
      "[[1. 0.]] 3100 100\n",
      "[[1. 0.]] 6846 9319\n",
      "[[1. 0.]] 1781 1932\n",
      "[[1. 0.]] 3817 2679\n",
      "[[1. 0.]] 3086 2866\n",
      "[[1. 0.]] 2242 1140\n",
      "[[1. 0.]] 2588 100\n",
      "[[1. 0.]] 100 4490\n",
      "[[1. 0.]] 1140 1781\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 1932 2588\n",
      "[[1. 0.]] 2280 3817\n",
      "[[1. 0.]] 9319 3100\n",
      "[[1. 0.]] 4490 3086\n",
      "[[1. 0.]] 100 7928\n",
      "[[1. 0.]] 6735 2242\n",
      "[[1. 0.]] 2679 9035\n",
      "[[1. 0.]] 2866 6846\n",
      "[[1. 0.]] 2588 9319\n",
      "[[1. 0.]] 1140 3086\n",
      "[[1. 0.]] 2679 6735\n",
      "[[1. 0.]] 3100 2866\n",
      "[[1. 0.]] 9035 1932\n",
      "[[1. 0.]] 3817 2242\n",
      "[[1. 0.]] 7928 4490\n",
      "[[1. 0.]] 100 1140\n",
      "[[1. 0.]] 1781 100\n",
      "[[1. 0.]] 3086 100\n",
      "[[1. 0.]] 1140 6846\n",
      "[[1. 0.]] 2242 2280\n",
      "[[1. 0.]] 1932 3086\n",
      "[[1. 0.]] 6735 3817\n",
      "[[1. 0.]] 100 2679\n",
      "[[1. 0.]] 9319 2866\n",
      "[[1. 0.]] 4490 2588\n",
      "[[1. 0.]] 7928 100\n",
      "[[1. 0.]] 1781 3100\n",
      "[[1. 0.]] 100 9035\n",
      "[[1. 0.]] 2866 4490\n",
      "[[1. 0.]] 6846 100\n",
      "[[1. 0.]] 9035 7928\n",
      "[[1. 0.]] 3100 3086\n",
      "[[1. 0.]] 2679 2242\n",
      "[[1. 0.]] 2588 1140\n",
      "[[1. 0.]] 3817 100\n",
      "[[1. 0.]] 2280 1932\n",
      "[[1. 0.]] 6735 9319\n",
      "[[1. 0.]] 100 1781\n",
      "[[1. 0.]] 6846 2588\n",
      "[[1. 0.]] 3086 3817\n",
      "[[1. 0.]] 100 2679\n",
      "[[1. 0.]] 4490 3100\n",
      "[[1. 0.]] 100 2280\n",
      "[[1. 0.]] 1140 2866\n",
      "[[1. 0.]] 1781 9035\n",
      "[[1. 0.]] 1932 6735\n",
      "[[1. 0.]] 9319 100\n",
      "[[1. 0.]] 7928 2242\n",
      "[[1. 0.]] 1140 4490\n",
      "[[1. 0.]] 2242 100\n",
      "[[1. 0.]] 2679 1932\n",
      "[[1. 0.]] 3817 7928\n",
      "[[1. 0.]] 9035 2866\n",
      "[[1. 0.]] 100 3100\n",
      "[[1. 0.]] 2588 3086\n",
      "[[1. 0.]] 2280 1781\n",
      "[[1. 0.]] 6735 6846\n",
      "[[1. 0.]] 100 9319\n",
      "[[1. 0.]] 100 1140\n",
      "[[1. 0.]] 2866 100\n",
      "[[1. 0.]] 3086 6735\n",
      "[[1. 0.]] 9319 2679\n",
      "[[1. 0.]] 6846 2242\n",
      "[[1. 0.]] 4490 2280\n",
      "[[1. 0.]] 7928 1932\n",
      "[[1. 0.]] 1781 3817\n",
      "[[1. 0.]] 3100 9035\n",
      "[[1. 0.]] 2588 100\n",
      "[[1. 0.]] 6846 2280\n",
      "[[1. 0.]] 6735 100\n",
      "[[1. 0.]] 2679 7928\n",
      "[[1. 0.]] 3817 2588\n",
      "[[1. 0.]] 2280 9319\n",
      "[[1. 0.]] 2242 3086\n",
      "[[1. 0.]] 100 1781\n",
      "[[1. 0.]] 1932 2866\n",
      "[[1. 0.]] 1140 3100\n",
      "[[1. 0.]] 100 6846\n",
      "[[1. 0.]] 9035 4490\n",
      "[[1. 0.]] 1781 2242\n",
      "[[1. 0.]] 100 1932\n",
      "[[1. 0.]] 7928 6735\n",
      "[[1. 0.]] 3100 2280\n",
      "[[1. 0.]] 9319 1140\n",
      "[[1. 0.]] 2588 2679\n",
      "[[1. 0.]] 3086 100\n",
      "[[1. 0.]] 2866 100\n",
      "[[1. 0.]] 6846 9035\n",
      "[[1. 0.]] 4490 3817\n",
      "[[1. 0.]] 1140 100\n",
      "[[1. 0.]] 100 3100\n",
      "[[1. 0.]] 2242 9319\n",
      "[[1. 0.]] 2679 4490\n",
      "[[1. 0.]] 1932 6846\n",
      "[[1. 0.]] 6735 1781\n",
      "[[1. 0.]] 6846 100\n",
      "[[1. 0.]] 100 3817\n",
      "[[1. 0.]] 1781 7928\n",
      "[[1. 0.]] 2866 6735\n",
      "[[1. 0.]] 100 2242\n",
      "[[1. 0.]] 4490 1932\n",
      "[[1. 0.]] 2588 2280\n",
      "[[1. 0.]] 3100 2679\n",
      "[[1. 0.]] 9319 9035\n",
      "[[1. 0.]] 3086 1140\n",
      "[[1. 0.]] 100 3507\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 100 3507\n",
      "[[1. 0.]] 1092 4858\n",
      "[[1. 0.]] 423 100\n",
      "[[1. 0.]] 178 100\n",
      "[[1. 0.]] 498 74\n",
      "[[1. 0.]] 63 5551\n",
      "[[1. 0.]] 603 100\n",
      "[[1. 0.]] 832 136\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 119 1054\n",
      "[[1. 0.]] 316 244\n",
      "[[1. 0.]] 890 2030\n",
      "[[1. 0.]] 1735 3545\n",
      "[[1. 0.]] 3493 210\n",
      "[[1. 0.]] 409 2769\n",
      "[[1. 0.]] 195 135\n",
      "[[1. 0.]] 100 651\n",
      "[[1. 0.]] 100 178\n",
      "[[1. 0.]] 244 316\n",
      "[[1. 0.]] 136 832\n",
      "[[1. 0.]] 74 498\n",
      "[[1. 0.]] 100 603\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 135 195\n",
      "[[1. 0.]] 100 423\n",
      "[[1. 0.]] 1054 119\n",
      "[[1. 0.]] 2769 409\n",
      "[[1. 0.]] 3545 1735\n",
      "[[1. 0.]] 4858 1092\n",
      "[[1. 0.]] 2030 890\n",
      "[[1. 0.]] 210 3493\n",
      "[[1. 0.]] 651 100\n",
      "[[1. 0.]] 5551 63\n",
      "[[1. 0.]] 2877 6497\n",
      "[[1. 0.]] 244 2478\n",
      "[[1. 0.]] 4032 100\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 210 3270\n",
      "[[1. 0.]] 890 2769\n",
      "[[1. 0.]] 1735 136\n",
      "[[1. 0.]] 4858 2302\n",
      "[[1. 0.]] 651 100\n",
      "[[1. 0.]] 195 1054\n",
      "[[1. 0.]] 100 498\n",
      "[[1. 0.]] 5551 178\n",
      "[[1. 0.]] 178 5551\n",
      "[[1. 0.]] 3270 210\n",
      "[[1. 0.]] 2302 4858\n",
      "[[1. 0.]] 136 1735\n",
      "[[1. 0.]] 100 4032\n",
      "[[1. 0.]] 2478 244\n",
      "[[1. 0.]] 6497 2877\n",
      "[[1. 0.]] 498 100\n",
      "[[1. 0.]] 2769 890\n",
      "[[1. 0.]] 1054 195\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 3270 1054\n",
      "[[1. 0.]] 3673 8164\n",
      "[[1. 0.]] 2478 1735\n",
      "[[1. 0.]] 8036 4168\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 5313 6206\n",
      "[[1. 0.]] 100 6497\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 4858 5551\n",
      "[[1. 0.]] 651 2769\n",
      "[[1. 0.]] 1054 3270\n",
      "[[1. 0.]] 2769 651\n",
      "[[1. 0.]] 4168 8036\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 1735 2478\n",
      "[[1. 0.]] 8164 3673\n",
      "[[1. 0.]] 6497 100\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 5551 4858\n",
      "[[1. 0.]] 6206 5313\n",
      "[[1. 0.]] 4858 3612\n",
      "[[1. 0.]] 3270 8164\n",
      "[[1. 0.]] 100 8036\n",
      "[[1. 0.]] 3132 100\n",
      "[[1. 0.]] 2478 2769\n",
      "[[1. 0.]] 6497 5313\n",
      "[[1. 0.]] 100 3132\n",
      "[[1. 0.]] 2769 2478\n",
      "[[1. 0.]] 5313 6497\n",
      "[[1. 0.]] 3612 4858\n",
      "[[1. 0.]] 8164 3270\n",
      "[[1. 0.]] 8036 100\n",
      "[[1. 0.]] 9035 3612\n",
      "[[1. 0.]] 6154 6351\n",
      "[[1. 0.]] 100 14695\n",
      "[[1. 0.]] 100 2929\n",
      "[[1. 0.]] 7276 13105\n",
      "[[1. 0.]] 6562 9221\n",
      "[[1. 0.]] 8832 9770\n",
      "[[1. 0.]] 8164 4207\n",
      "[[1. 0.]] 8036 3647\n",
      "[[1. 0.]] 6497 6821\n",
      "[[1. 0.]] 9495 8949\n",
      "[[1. 0.]] 10885 100\n",
      "[[1. 0.]] 100 10390\n",
      "[[1. 0.]] 2478 7928\n",
      "[[1. 0.]] 8083 100\n",
      "[[1. 0.]] 9329 9319\n",
      "[[1. 0.]] 8949 8036\n",
      "[[1. 0.]] 7928 100\n",
      "[[1. 0.]] 3647 9495\n",
      "[[1. 0.]] 6821 10885\n",
      "[[1. 0.]] 100 6497\n",
      "[[1. 0.]] 10390 2478\n",
      "[[1. 0.]] 9319 8083\n",
      "[[1. 0.]] 100 9329\n",
      "[[1. 0.]] 2929 100\n",
      "[[1. 0.]] 3612 7276\n",
      "[[1. 0.]] 14695 100\n",
      "[[1. 0.]] 13105 9035\n",
      "[[1. 0.]] 6351 6562\n",
      "[[1. 0.]] 9221 6154\n",
      "[[1. 0.]] 4207 8832\n",
      "[[1. 0.]] 9770 8164\n",
      "[[1. 0.]] 100 2478\n",
      "[[1. 0.]] 9329 8083\n",
      "[[1. 0.]] 3647 8949\n",
      "[[1. 0.]] 8036 9495\n",
      "[[1. 0.]] 6821 100\n",
      "[[1. 0.]] 6497 10885\n",
      "[[1. 0.]] 10390 7928\n",
      "[[1. 0.]] 9319 100\n",
      "[[1. 0.]] 9221 6351\n",
      "[[1. 0.]] 8164 8832\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 2929 14695\n",
      "[[1. 0.]] 9035 7276\n",
      "[[1. 0.]] 3612 13105\n",
      "[[1. 0.]] 6562 6154\n",
      "[[1. 0.]] 4207 9770\n",
      "[[1. 0.]] 13105 3612\n",
      "[[1. 0.]] 6351 9221\n",
      "[[1. 0.]] 14695 2929\n",
      "[[1. 0.]] 100 100\n",
      "[[1. 0.]] 7276 9035\n",
      "[[1. 0.]] 6154 6562\n",
      "[[1. 0.]] 8832 8164\n",
      "[[1. 0.]] 9770 4207\n",
      "[[1. 0.]] 10885 6497\n",
      "[[1. 0.]] 100 9319\n",
      "[[1. 0.]] 9495 8036\n",
      "[[1. 0.]] 8949 3647\n",
      "[[1. 0.]] 100 6821\n",
      "[[1. 0.]] 7928 10390\n",
      "[[1. 0.]] 2478 100\n",
      "[[1. 0.]] 8083 9329\n",
      "[[1. 0.]] 3647 8036\n",
      "[[1. 0.]] 100 8083\n",
      "[[1. 0.]] 8949 9495\n",
      "[[1. 0.]] 6821 6497\n",
      "[[1. 0.]] 100 10885\n",
      "[[1. 0.]] 10390 100\n",
      "[[1. 0.]] 7928 2478\n",
      "[[1. 0.]] 9319 9329\n",
      "[[1. 0.]] 6351 6154\n",
      "[[1. 0.]] 9770 8832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]] 14695 100\n",
      "[[1. 0.]] 2929 100\n",
      "[[1. 0.]] 13105 7276\n",
      "[[1. 0.]] 3612 9035\n",
      "[[1. 0.]] 9221 6562\n",
      "[[1. 0.]] 4207 8164\n",
      "[[1. 0.]] 100 2929\n",
      "[[1. 0.]] 100 14695\n",
      "[[1. 0.]] 7276 3612\n",
      "[[1. 0.]] 9035 13105\n",
      "[[1. 0.]] 6154 9221\n",
      "[[1. 0.]] 6562 6351\n",
      "[[1. 0.]] 8832 4207\n",
      "[[1. 0.]] 8164 9770\n",
      "[[1. 0.]] 100 7928\n",
      "[[1. 0.]] 2478 10390\n",
      "[[1. 0.]] 9495 3647\n",
      "[[1. 0.]] 8036 8949\n",
      "[[1. 0.]] 10885 6821\n",
      "[[1. 0.]] 6497 100\n",
      "[[1. 0.]] 8083 9319\n",
      "[[1. 0.]] 9329 100\n",
      "[[1. 0.]] 7276 9495\n",
      "[[1. 0.]] 9329 14695\n",
      "[[1. 0.]] 7928 9770\n",
      "[[1. 0.]] 6821 9221\n",
      "[[1. 0.]] 8832 10885\n",
      "[[1. 0.]] 100 13105\n",
      "[[1. 0.]] 8949 10390\n",
      "[[1. 0.]] 6154 9319\n",
      "[[1. 0.]] 9770 7928\n",
      "[[1. 0.]] 9221 6821\n",
      "[[1. 0.]] 9495 7276\n",
      "[[1. 0.]] 14695 9329\n"
     ]
    }
   ],
   "source": [
    "unique = train_csv.values\n",
    "goalHHalf_time = []\n",
    "for i in unique:\n",
    "    puissance_homeTeam = i[15]\n",
    "    puissance_awayTeam = i[16]\n",
    "    win_cons_home = i[11]\n",
    "    win_cons_away = i[12]\n",
    "    lose_cons_home = i[13]\n",
    "    lose_cons_away= i[14]\n",
    "    predictions1 = model.predict(np.array([[win_cons_home,win_cons_away,lose_cons_home,lose_cons_away,puissance_homeTeam,puissance_awayTeam]])) # predictions avec puissance de teams au hasard\n",
    "    goal = predictions1\n",
    "    goalHHalf_time.append(goal)\n",
    "    print(goal,puissance_homeTeam,puissance_awayTeam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_csv = {'date':train_csv.date,'id_HomeTeam':train_csv.idHomeTeam,'id_AwayTeam':train_csv.idAwayTeam,'homeTeam':train_csv.homeTeam,'AwayTeam':train_csv.awayTeam,'goalHomeTeam_HalfTime':predictions1[0][0],'goalAwayTeam_HalfTime':predictions1[0][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_HomeTeam</th>\n",
       "      <th>id_AwayTeam</th>\n",
       "      <th>homeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>goalHomeTeam_HalfTime</th>\n",
       "      <th>goalAwayTeam_HalfTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>548</td>\n",
       "      <td>523</td>\n",
       "      <td>AS Monaco FC</td>\n",
       "      <td>Olympique Lyonnais</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>516</td>\n",
       "      <td>547</td>\n",
       "      <td>Olympique de Marseille</td>\n",
       "      <td>Stade de Reims</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>518</td>\n",
       "      <td>529</td>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>Stade Rennais FC 1901</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>522</td>\n",
       "      <td>530</td>\n",
       "      <td>OGC Nice</td>\n",
       "      <td>Amiens SC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>512</td>\n",
       "      <td>511</td>\n",
       "      <td>Stade Brestois 29</td>\n",
       "      <td>Toulouse FC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1286</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>523</td>\n",
       "      <td>109</td>\n",
       "      <td>Olympique Lyonnais</td>\n",
       "      <td>Juventus FC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1287</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>Valencia CF</td>\n",
       "      <td>Atalanta BC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1288</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>721</td>\n",
       "      <td>73</td>\n",
       "      <td>RB Leipzig</td>\n",
       "      <td>Tottenham Hotspur FC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1289</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>524</td>\n",
       "      <td>4</td>\n",
       "      <td>Paris Saint-Germain FC</td>\n",
       "      <td>BV Borussia 09 Dortmund</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>Liverpool FC</td>\n",
       "      <td>Club AtlÃ©tico de Madrid</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1291 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  id_HomeTeam  id_AwayTeam                homeTeam  \\\n",
       "0     2019-08-09          548          523            AS Monaco FC   \n",
       "1     2019-08-10          516          547  Olympique de Marseille   \n",
       "2     2019-08-10          518          529         Montpellier HSC   \n",
       "3     2019-08-10          522          530                OGC Nice   \n",
       "4     2019-08-10          512          511       Stade Brestois 29   \n",
       "...          ...          ...          ...                     ...   \n",
       "1286  2020-02-26          523          109      Olympique Lyonnais   \n",
       "1287  2020-03-10           95          102             Valencia CF   \n",
       "1288  2020-03-10          721           73              RB Leipzig   \n",
       "1289  2020-03-11          524            4  Paris Saint-Germain FC   \n",
       "1290  2020-03-11           64           78            Liverpool FC   \n",
       "\n",
       "                     AwayTeam  goalHomeTeam_HalfTime  goalAwayTeam_HalfTime  \n",
       "0          Olympique Lyonnais                    1.0                    0.0  \n",
       "1              Stade de Reims                    1.0                    0.0  \n",
       "2       Stade Rennais FC 1901                    1.0                    0.0  \n",
       "3                   Amiens SC                    1.0                    0.0  \n",
       "4                 Toulouse FC                    1.0                    0.0  \n",
       "...                       ...                    ...                    ...  \n",
       "1286              Juventus FC                    1.0                    0.0  \n",
       "1287              Atalanta BC                    1.0                    0.0  \n",
       "1288     Tottenham Hotspur FC                    1.0                    0.0  \n",
       "1289  BV Borussia 09 Dortmund                    1.0                    0.0  \n",
       "1290  Club AtlÃ©tico de Madrid                    1.0                    0.0  \n",
       "\n",
       "[1291 rows x 7 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(res_csv)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train_csv.drop(['idHomeTeam','idAwayTeam','score','homeTeam','awayTeam','date','goalHomeTeam_HalfTime','goalAwayTeam_HalfTime','goalHomeTeam_FullTime','goalAwayTeam_FullTime'],axis=1).values\n",
    "# X = X[:,1:]\n",
    "# Y = train_csv.drop(['idHomeTeam','idAwayTeam','score','homeTeam','awayTeam','date','goalHomeTeam_FullTime','goalAwayTeam_FullTime','win_cons_home','win_cons_away','lose_cons_home','lose_cons_away','puissance_homeTeam','puissance_awayTeam'],axis=1).values\n",
    "# Y = Y[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
