{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.datasets import *\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path=\"C:\\\\Users\\\\Amrta\\\\Documents\\\\GitHub\\\\projetannuel4IABD2\\\\ETAPE_3\\\\Scripts_Recup_Data\\\\\"\n",
    "open_folder = os.listdir(main_path)\n",
    "Data_base_learning = main_path+open_folder[2]\n",
    "Points_equipe = main_path+open_folder[3]\n",
    "Teams_puissance = main_path+open_folder[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>puissance_homeTeam</th>\n",
       "      <th>puissance_awayTeam</th>\n",
       "      <th>win_cons_home</th>\n",
       "      <th>win_cons_away</th>\n",
       "      <th>lose_cons_home</th>\n",
       "      <th>lose_cons_away</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2409</td>\n",
       "      <td>6154</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4008</td>\n",
       "      <td>3054</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3029</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2803</td>\n",
       "      <td>2045</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2156</td>\n",
       "      <td>1065</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1286</td>\n",
       "      <td>1714</td>\n",
       "      <td>6154</td>\n",
       "      <td>9319</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1287</td>\n",
       "      <td>1715</td>\n",
       "      <td>9770</td>\n",
       "      <td>7928</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1288</td>\n",
       "      <td>1716</td>\n",
       "      <td>9221</td>\n",
       "      <td>6821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1289</td>\n",
       "      <td>1717</td>\n",
       "      <td>9495</td>\n",
       "      <td>7276</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>1718</td>\n",
       "      <td>14695</td>\n",
       "      <td>9329</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1291 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  puissance_homeTeam  puissance_awayTeam  win_cons_home  \\\n",
       "0              0                2409                6154             -1   \n",
       "1              1                4008                3054             -1   \n",
       "2              2                3029                 100             -1   \n",
       "3              3                2803                2045             -1   \n",
       "4              4                2156                1065             -1   \n",
       "...          ...                 ...                 ...            ...   \n",
       "1286        1714                6154                9319              1   \n",
       "1287        1715                9770                7928              0   \n",
       "1288        1716                9221                6821              1   \n",
       "1289        1717                9495                7276              2   \n",
       "1290        1718               14695                9329              1   \n",
       "\n",
       "      win_cons_away  lose_cons_home  lose_cons_away  score  \n",
       "0                -1              -1              -1    2.0  \n",
       "1                -1              -1              -1    2.0  \n",
       "2                -1              -1              -1    2.0  \n",
       "3                -1              -1              -1    1.0  \n",
       "4                -1              -1              -1    0.0  \n",
       "...             ...             ...             ...    ...  \n",
       "1286              2               0               0    1.0  \n",
       "1287              4               0               0    2.0  \n",
       "1288              0               0               0    1.0  \n",
       "1289              2               0               0    1.0  \n",
       "1290              0               0               0    2.0  \n",
       "\n",
       "[1291 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(Data_base_learning,sep=\";\",encoding=\"utf-8\")\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., ..., 1., 1., 2.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_csv.drop(['score'],axis=1).values\n",
    "X = X[:,1:]\n",
    "Y = train_csv['score'].values\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032, 6) (1032,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test=train_test_split(X,Y, test_size=0.2)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in y_train:\n",
    "#      print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(3, input_dim=x_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(3, input_dim=x_train.shape[1], activation='linear'))\n",
    "    model.add(Dense(3, input_dim=x_train.shape[1], activation='linear'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                  optimizer=Adam(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1032 samples, validate on 259 samples\n",
      "Epoch 1/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0155 - accuracy: 0.5010 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 2/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0148 - accuracy: 0.5000 - val_loss: 0.9706 - val_accuracy: 0.5946\n",
      "Epoch 3/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0151 - accuracy: 0.5000 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 4/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 5/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0156 - accuracy: 0.5010 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 6/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0150 - accuracy: 0.5019 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 7/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0148 - accuracy: 0.5019 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 8/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 9/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0147 - accuracy: 0.5019 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 10/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0147 - accuracy: 0.4971 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 11/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0148 - accuracy: 0.5000 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 12/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0151 - accuracy: 0.5029 - val_loss: 0.9720 - val_accuracy: 0.5985\n",
      "Epoch 13/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0157 - accuracy: 0.5029 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 14/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0154 - accuracy: 0.5048 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 15/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0145 - accuracy: 0.5019 - val_loss: 0.9727 - val_accuracy: 0.5946\n",
      "Epoch 16/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0156 - accuracy: 0.5068 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 17/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0147 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 18/500\n",
      "1032/1032 [==============================] - 0s 65us/sample - loss: 1.0147 - accuracy: 0.5039 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 19/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0163 - accuracy: 0.5010 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 20/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0154 - accuracy: 0.5010 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 21/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0156 - accuracy: 0.5019 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 22/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0150 - accuracy: 0.5010 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 23/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0152 - accuracy: 0.5029 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 24/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0148 - accuracy: 0.4990 - val_loss: 0.9709 - val_accuracy: 0.6023\n",
      "Epoch 25/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0149 - accuracy: 0.5048 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 26/500\n",
      "1032/1032 [==============================] - 0s 45us/sample - loss: 1.0151 - accuracy: 0.5010 - val_loss: 0.9720 - val_accuracy: 0.5985\n",
      "Epoch 27/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0151 - accuracy: 0.5010 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 28/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0146 - accuracy: 0.5029 - val_loss: 0.9717 - val_accuracy: 0.5985\n",
      "Epoch 29/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0155 - accuracy: 0.4990 - val_loss: 0.9711 - val_accuracy: 0.6023\n",
      "Epoch 30/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0156 - accuracy: 0.5000 - val_loss: 0.9727 - val_accuracy: 0.5946\n",
      "Epoch 31/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0152 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 32/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0155 - accuracy: 0.5010 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 33/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0144 - accuracy: 0.5019 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 34/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0153 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 35/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0149 - accuracy: 0.5019 - val_loss: 0.9720 - val_accuracy: 0.5985\n",
      "Epoch 36/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0151 - accuracy: 0.4981 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 37/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0152 - accuracy: 0.5039 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 38/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0147 - accuracy: 0.5019 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 39/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0154 - accuracy: 0.5010 - val_loss: 0.9723 - val_accuracy: 0.5946\n",
      "Epoch 40/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0145 - accuracy: 0.5029 - val_loss: 0.9710 - val_accuracy: 0.5985\n",
      "Epoch 41/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0171 - accuracy: 0.5019 - val_loss: 0.9729 - val_accuracy: 0.5946\n",
      "Epoch 42/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0145 - accuracy: 0.5029 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 43/500\n",
      "1032/1032 [==============================] - 0s 58us/sample - loss: 1.0154 - accuracy: 0.5029 - val_loss: 0.9709 - val_accuracy: 0.5985\n",
      "Epoch 44/500\n",
      "1032/1032 [==============================] - 0s 46us/sample - loss: 1.0152 - accuracy: 0.5039 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 45/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9726 - val_accuracy: 0.5946\n",
      "Epoch 46/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0156 - accuracy: 0.5039 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 47/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0151 - accuracy: 0.5039 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 48/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0159 - accuracy: 0.4990 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 49/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0150 - accuracy: 0.5000 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 50/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0146 - accuracy: 0.5000 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 51/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0149 - accuracy: 0.5000 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 52/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0155 - accuracy: 0.5000 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 53/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0150 - accuracy: 0.5039 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 54/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0154 - accuracy: 0.5010 - val_loss: 0.9721 - val_accuracy: 0.5985\n",
      "Epoch 55/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0150 - accuracy: 0.5039 - val_loss: 0.9713 - val_accuracy: 0.5985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "1032/1032 [==============================] - 0s 45us/sample - loss: 1.0164 - accuracy: 0.5000 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 57/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0160 - accuracy: 0.4981 - val_loss: 0.9710 - val_accuracy: 0.5985\n",
      "Epoch 58/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0157 - accuracy: 0.4990 - val_loss: 0.9720 - val_accuracy: 0.5985\n",
      "Epoch 59/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0154 - accuracy: 0.5019 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 60/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0158 - accuracy: 0.5039 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 61/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0149 - accuracy: 0.5039 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 62/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0156 - accuracy: 0.5010 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 63/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0149 - accuracy: 0.5029 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 64/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 65/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 66/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0153 - accuracy: 0.4990 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 67/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0151 - accuracy: 0.5039 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 68/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0147 - accuracy: 0.5019 - val_loss: 0.9721 - val_accuracy: 0.5985\n",
      "Epoch 69/500\n",
      "1032/1032 [==============================] - 0s 44us/sample - loss: 1.0148 - accuracy: 0.5010 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 70/500\n",
      "1032/1032 [==============================] - 0s 59us/sample - loss: 1.0149 - accuracy: 0.5010 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 71/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0147 - accuracy: 0.5019 - val_loss: 0.9723 - val_accuracy: 0.5946\n",
      "Epoch 72/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0156 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 73/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0150 - accuracy: 0.5000 - val_loss: 0.9728 - val_accuracy: 0.5946\n",
      "Epoch 74/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0146 - accuracy: 0.5029 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 75/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0148 - accuracy: 0.5010 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 76/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0151 - accuracy: 0.5029 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 77/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0154 - accuracy: 0.5029 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 78/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0155 - accuracy: 0.5000 - val_loss: 0.9729 - val_accuracy: 0.5946\n",
      "Epoch 79/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0170 - accuracy: 0.4971 - val_loss: 0.9717 - val_accuracy: 0.5985\n",
      "Epoch 80/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0152 - accuracy: 0.5029 - val_loss: 0.9732 - val_accuracy: 0.5946\n",
      "Epoch 81/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0155 - accuracy: 0.5039 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 82/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0147 - accuracy: 0.4990 - val_loss: 0.9723 - val_accuracy: 0.5985\n",
      "Epoch 83/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0146 - accuracy: 0.5039 - val_loss: 0.9730 - val_accuracy: 0.5946\n",
      "Epoch 84/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0171 - accuracy: 0.4990 - val_loss: 0.9717 - val_accuracy: 0.5985\n",
      "Epoch 85/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0154 - accuracy: 0.5010 - val_loss: 0.9722 - val_accuracy: 0.5985\n",
      "Epoch 86/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0144 - accuracy: 0.5000 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 87/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0152 - accuracy: 0.5000 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 88/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0147 - accuracy: 0.5010 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 89/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0163 - accuracy: 0.4981 - val_loss: 0.9709 - val_accuracy: 0.6023\n",
      "Epoch 90/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0156 - accuracy: 0.5019 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 91/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0152 - accuracy: 0.5048 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 92/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0151 - accuracy: 0.5039 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 93/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0162 - accuracy: 0.4971 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 94/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0206 - accuracy: 0.5010 - val_loss: 0.9714 - val_accuracy: 0.6023\n",
      "Epoch 95/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0173 - accuracy: 0.5019 - val_loss: 0.9713 - val_accuracy: 0.6023\n",
      "Epoch 96/500\n",
      "1032/1032 [==============================] - 0s 55us/sample - loss: 1.0160 - accuracy: 0.4990 - val_loss: 0.9721 - val_accuracy: 0.5985\n",
      "Epoch 97/500\n",
      "1032/1032 [==============================] - 0s 67us/sample - loss: 1.0151 - accuracy: 0.5010 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 98/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0153 - accuracy: 0.5019 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 99/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0146 - accuracy: 0.5000 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 100/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0152 - accuracy: 0.5039 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 101/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0145 - accuracy: 0.5000 - val_loss: 0.9728 - val_accuracy: 0.5946\n",
      "Epoch 102/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0148 - accuracy: 0.4990 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 103/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0149 - accuracy: 0.5039 - val_loss: 0.9721 - val_accuracy: 0.5985\n",
      "Epoch 104/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0152 - accuracy: 0.5010 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 105/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0150 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 106/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0155 - accuracy: 0.5029 - val_loss: 0.9708 - val_accuracy: 0.5946\n",
      "Epoch 107/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0150 - accuracy: 0.5029 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 108/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0160 - accuracy: 0.5029 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 109/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 110/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0168 - accuracy: 0.5048 - val_loss: 0.9710 - val_accuracy: 0.6023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 112/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0148 - accuracy: 0.5019 - val_loss: 0.9722 - val_accuracy: 0.5985\n",
      "Epoch 113/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0153 - accuracy: 0.5029 - val_loss: 0.9707 - val_accuracy: 0.5985\n",
      "Epoch 114/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0164 - accuracy: 0.5029 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 115/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0149 - accuracy: 0.5000 - val_loss: 0.9710 - val_accuracy: 0.5985\n",
      "Epoch 116/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0155 - accuracy: 0.4990 - val_loss: 0.9728 - val_accuracy: 0.5946\n",
      "Epoch 117/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0176 - accuracy: 0.5039 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 118/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0148 - accuracy: 0.5029 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 119/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0150 - accuracy: 0.5019 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 120/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0148 - accuracy: 0.5000 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 121/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0146 - accuracy: 0.4990 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 122/500\n",
      "1032/1032 [==============================] - 0s 56us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 123/500\n",
      "1032/1032 [==============================] - 0s 52us/sample - loss: 1.0147 - accuracy: 0.5029 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 124/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0147 - accuracy: 0.5019 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 125/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0151 - accuracy: 0.5029 - val_loss: 0.9721 - val_accuracy: 0.5985\n",
      "Epoch 126/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0147 - accuracy: 0.5039 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 127/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0151 - accuracy: 0.5010 - val_loss: 0.9720 - val_accuracy: 0.5985\n",
      "Epoch 128/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0150 - accuracy: 0.5000 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 129/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0155 - accuracy: 0.5019 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 130/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0149 - accuracy: 0.5019 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 131/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0148 - accuracy: 0.5010 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 132/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0147 - accuracy: 0.5000 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 133/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0145 - accuracy: 0.5000 - val_loss: 0.9722 - val_accuracy: 0.5985\n",
      "Epoch 134/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0147 - accuracy: 0.5000 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 135/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0166 - accuracy: 0.5010 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 136/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0159 - accuracy: 0.5019 - val_loss: 0.9709 - val_accuracy: 0.5985\n",
      "Epoch 137/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0158 - accuracy: 0.5019 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 138/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0162 - accuracy: 0.5029 - val_loss: 0.9707 - val_accuracy: 0.5985\n",
      "Epoch 139/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0169 - accuracy: 0.5029 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 140/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0161 - accuracy: 0.5000 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 141/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0148 - accuracy: 0.5010 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 142/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0150 - accuracy: 0.5000 - val_loss: 0.9703 - val_accuracy: 0.6023\n",
      "Epoch 143/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0156 - accuracy: 0.4990 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 144/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0150 - accuracy: 0.4981 - val_loss: 0.9743 - val_accuracy: 0.5946\n",
      "Epoch 145/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0149 - accuracy: 0.4990 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 146/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0152 - accuracy: 0.4981 - val_loss: 0.9707 - val_accuracy: 0.5946\n",
      "Epoch 147/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0156 - accuracy: 0.5010 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 148/500\n",
      "1032/1032 [==============================] - 0s 68us/sample - loss: 1.0155 - accuracy: 0.5010 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 149/500\n",
      "1032/1032 [==============================] - 0s 50us/sample - loss: 1.0151 - accuracy: 0.5039 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 150/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0148 - accuracy: 0.5010 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 151/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0163 - accuracy: 0.5029 - val_loss: 0.9723 - val_accuracy: 0.5985\n",
      "Epoch 152/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0151 - accuracy: 0.5039 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 153/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0151 - accuracy: 0.5039 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 154/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0156 - accuracy: 0.5019 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 155/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0148 - accuracy: 0.5048 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 156/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0163 - accuracy: 0.5029 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 157/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0157 - accuracy: 0.4990 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 158/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0151 - accuracy: 0.5000 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 159/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0148 - accuracy: 0.4990 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 160/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0155 - accuracy: 0.5058 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 161/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0184 - accuracy: 0.5010 - val_loss: 0.9755 - val_accuracy: 0.5985\n",
      "Epoch 162/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0178 - accuracy: 0.4981 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 163/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0160 - accuracy: 0.5019 - val_loss: 0.9720 - val_accuracy: 0.5985\n",
      "Epoch 164/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0150 - accuracy: 0.5019 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0156 - accuracy: 0.5010 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 166/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0150 - accuracy: 0.5019 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 167/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0167 - accuracy: 0.5029 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 168/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0185 - accuracy: 0.4990 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 169/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0157 - accuracy: 0.5000 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 170/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0157 - accuracy: 0.5039 - val_loss: 0.9722 - val_accuracy: 0.5985\n",
      "Epoch 171/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 172/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0176 - accuracy: 0.5039 - val_loss: 0.9717 - val_accuracy: 0.5985\n",
      "Epoch 173/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0158 - accuracy: 0.5000 - val_loss: 0.9724 - val_accuracy: 0.5985\n",
      "Epoch 174/500\n",
      "1032/1032 [==============================] - 0s 63us/sample - loss: 1.0146 - accuracy: 0.5000 - val_loss: 0.9738 - val_accuracy: 0.5946\n",
      "Epoch 175/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0157 - accuracy: 0.4990 - val_loss: 0.9710 - val_accuracy: 0.5985\n",
      "Epoch 176/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0155 - accuracy: 0.5010 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 177/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0160 - accuracy: 0.4961 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 178/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0141 - accuracy: 0.5029 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 179/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0155 - accuracy: 0.5019 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 180/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0150 - accuracy: 0.5039 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 181/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0145 - accuracy: 0.5029 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 182/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0148 - accuracy: 0.5000 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 183/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0149 - accuracy: 0.5048 - val_loss: 0.9720 - val_accuracy: 0.5985\n",
      "Epoch 184/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0154 - accuracy: 0.4981 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 185/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 186/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0155 - accuracy: 0.5010 - val_loss: 0.9731 - val_accuracy: 0.5946\n",
      "Epoch 187/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0142 - accuracy: 0.5010 - val_loss: 0.9700 - val_accuracy: 0.6023\n",
      "Epoch 188/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0153 - accuracy: 0.4981 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 189/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0149 - accuracy: 0.5029 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 190/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0144 - accuracy: 0.5058 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 191/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0150 - accuracy: 0.4990 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 192/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0176 - accuracy: 0.5039 - val_loss: 0.9725 - val_accuracy: 0.5985\n",
      "Epoch 193/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0171 - accuracy: 0.5048 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 194/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0157 - accuracy: 0.4971 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 195/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0150 - accuracy: 0.5048 - val_loss: 0.9709 - val_accuracy: 0.5985\n",
      "Epoch 196/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0152 - accuracy: 0.5019 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 197/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0156 - accuracy: 0.5019 - val_loss: 0.9720 - val_accuracy: 0.5985\n",
      "Epoch 198/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0163 - accuracy: 0.4981 - val_loss: 0.9709 - val_accuracy: 0.5985\n",
      "Epoch 199/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0162 - accuracy: 0.4990 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 200/500\n",
      "1032/1032 [==============================] - 0s 69us/sample - loss: 1.0141 - accuracy: 0.5058 - val_loss: 0.9735 - val_accuracy: 0.5946\n",
      "Epoch 201/500\n",
      "1032/1032 [==============================] - 0s 44us/sample - loss: 1.0145 - accuracy: 0.5029 - val_loss: 0.9712 - val_accuracy: 0.5946\n",
      "Epoch 202/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0150 - accuracy: 0.5029 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 203/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 204/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0147 - accuracy: 0.5019 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 205/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0142 - accuracy: 0.5010 - val_loss: 0.9729 - val_accuracy: 0.5946\n",
      "Epoch 206/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0150 - accuracy: 0.5010 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 207/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0162 - accuracy: 0.5010 - val_loss: 0.9734 - val_accuracy: 0.5946\n",
      "Epoch 208/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0149 - accuracy: 0.5000 - val_loss: 0.9728 - val_accuracy: 0.5946\n",
      "Epoch 209/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0155 - accuracy: 0.5000 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 210/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0150 - accuracy: 0.5068 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 211/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0146 - accuracy: 0.5029 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 212/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0150 - accuracy: 0.5039 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 213/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0173 - accuracy: 0.5058 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 214/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0164 - accuracy: 0.5000 - val_loss: 0.9727 - val_accuracy: 0.5946\n",
      "Epoch 215/500\n",
      "1032/1032 [==============================] - 0s 45us/sample - loss: 1.0150 - accuracy: 0.5048 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 216/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0158 - accuracy: 0.5019 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 217/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0148 - accuracy: 0.5029 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 218/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0155 - accuracy: 0.5000 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 219/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0149 - accuracy: 0.5039 - val_loss: 0.9729 - val_accuracy: 0.5946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0166 - accuracy: 0.4981 - val_loss: 0.9731 - val_accuracy: 0.5985\n",
      "Epoch 221/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0170 - accuracy: 0.5039 - val_loss: 0.9717 - val_accuracy: 0.6023\n",
      "Epoch 222/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0154 - accuracy: 0.5010 - val_loss: 0.9705 - val_accuracy: 0.6023\n",
      "Epoch 223/500\n",
      "1032/1032 [==============================] - 0s 44us/sample - loss: 1.0150 - accuracy: 0.4990 - val_loss: 0.9738 - val_accuracy: 0.5946\n",
      "Epoch 224/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0147 - accuracy: 0.5029 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 225/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0143 - accuracy: 0.5000 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 226/500\n",
      "1032/1032 [==============================] - 0s 60us/sample - loss: 1.0150 - accuracy: 0.5010 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 227/500\n",
      "1032/1032 [==============================] - 0s 49us/sample - loss: 1.0149 - accuracy: 0.5039 - val_loss: 0.9730 - val_accuracy: 0.5946\n",
      "Epoch 228/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0146 - accuracy: 0.5019 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 229/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0143 - accuracy: 0.5029 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 230/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0146 - accuracy: 0.5048 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 231/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0145 - accuracy: 0.4990 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 232/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0150 - accuracy: 0.5010 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 233/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0158 - accuracy: 0.4990 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 234/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0144 - accuracy: 0.5019 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 235/500\n",
      "1032/1032 [==============================] - 0s 62us/sample - loss: 1.0151 - accuracy: 0.5039 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 236/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0155 - accuracy: 0.5029 - val_loss: 0.9726 - val_accuracy: 0.5985\n",
      "Epoch 237/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0144 - accuracy: 0.5010 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 238/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0159 - accuracy: 0.5010 - val_loss: 0.9724 - val_accuracy: 0.5985\n",
      "Epoch 239/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0150 - accuracy: 0.5029 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 240/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0151 - accuracy: 0.5039 - val_loss: 0.9717 - val_accuracy: 0.5985\n",
      "Epoch 241/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0153 - accuracy: 0.5039 - val_loss: 0.9737 - val_accuracy: 0.5946\n",
      "Epoch 242/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0148 - accuracy: 0.5019 - val_loss: 0.9705 - val_accuracy: 0.5985\n",
      "Epoch 243/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0150 - accuracy: 0.5019 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 244/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9721 - val_accuracy: 0.5985\n",
      "Epoch 245/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0146 - accuracy: 0.5000 - val_loss: 0.9733 - val_accuracy: 0.5946\n",
      "Epoch 246/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0151 - accuracy: 0.5058 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 247/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0161 - accuracy: 0.5000 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 248/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0155 - accuracy: 0.5019 - val_loss: 0.9712 - val_accuracy: 0.5946\n",
      "Epoch 249/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0156 - accuracy: 0.5010 - val_loss: 0.9726 - val_accuracy: 0.5946\n",
      "Epoch 250/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0151 - accuracy: 0.5010 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 251/500\n",
      "1032/1032 [==============================] - 0s 48us/sample - loss: 1.0150 - accuracy: 0.4990 - val_loss: 0.9727 - val_accuracy: 0.5946\n",
      "Epoch 252/500\n",
      "1032/1032 [==============================] - 0s 60us/sample - loss: 1.0147 - accuracy: 0.5000 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 253/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0149 - accuracy: 0.5029 - val_loss: 0.9710 - val_accuracy: 0.5985\n",
      "Epoch 254/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0167 - accuracy: 0.4990 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 255/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0162 - accuracy: 0.5029 - val_loss: 0.9729 - val_accuracy: 0.5946\n",
      "Epoch 256/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0202 - accuracy: 0.5010 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 257/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0166 - accuracy: 0.5019 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 258/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0157 - accuracy: 0.5019 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 259/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0147 - accuracy: 0.5010 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 260/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0150 - accuracy: 0.5029 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 261/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0147 - accuracy: 0.5010 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 262/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0145 - accuracy: 0.5010 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 263/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0166 - accuracy: 0.5058 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 264/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0183 - accuracy: 0.4981 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 265/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 266/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0156 - accuracy: 0.5010 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 267/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0140 - accuracy: 0.5010 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 268/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0148 - accuracy: 0.5019 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 269/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0154 - accuracy: 0.5010 - val_loss: 0.9709 - val_accuracy: 0.5985\n",
      "Epoch 270/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0153 - accuracy: 0.5039 - val_loss: 0.9706 - val_accuracy: 0.5985\n",
      "Epoch 271/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0156 - accuracy: 0.5039 - val_loss: 0.9739 - val_accuracy: 0.5946\n",
      "Epoch 272/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0150 - accuracy: 0.4981 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 273/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0144 - accuracy: 0.5010 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 274/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0149 - accuracy: 0.5010 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 275/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 276/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0149 - accuracy: 0.5039 - val_loss: 0.9717 - val_accuracy: 0.5985\n",
      "Epoch 277/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0153 - accuracy: 0.5019 - val_loss: 0.9708 - val_accuracy: 0.6023\n",
      "Epoch 278/500\n",
      "1032/1032 [==============================] - 0s 75us/sample - loss: 1.0149 - accuracy: 0.5029 - val_loss: 0.9712 - val_accuracy: 0.5946\n",
      "Epoch 279/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0147 - accuracy: 0.5029 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 280/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0149 - accuracy: 0.4990 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 281/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0146 - accuracy: 0.5019 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 282/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0145 - accuracy: 0.5029 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 283/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0150 - accuracy: 0.5019 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 284/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0149 - accuracy: 0.5019 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 285/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0204 - accuracy: 0.5000 - val_loss: 0.9726 - val_accuracy: 0.5985\n",
      "Epoch 286/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0166 - accuracy: 0.5039 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 287/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0184 - accuracy: 0.4990 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 288/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0152 - accuracy: 0.5019 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 289/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0143 - accuracy: 0.5019 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 290/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0172 - accuracy: 0.4971 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 291/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0154 - accuracy: 0.5048 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 292/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0156 - accuracy: 0.5010 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 293/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0177 - accuracy: 0.5019 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 294/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0148 - accuracy: 0.5058 - val_loss: 0.9739 - val_accuracy: 0.5946\n",
      "Epoch 295/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0148 - accuracy: 0.5019 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 296/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0170 - accuracy: 0.5078 - val_loss: 0.9706 - val_accuracy: 0.5869\n",
      "Epoch 297/500\n",
      "1032/1032 [==============================] - 0s 49us/sample - loss: 1.0159 - accuracy: 0.4981 - val_loss: 0.9723 - val_accuracy: 0.5946\n",
      "Epoch 298/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0145 - accuracy: 0.5019 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 299/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0147 - accuracy: 0.5029 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 300/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0146 - accuracy: 0.5000 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 301/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0147 - accuracy: 0.5039 - val_loss: 0.9716 - val_accuracy: 0.5985\n",
      "Epoch 302/500\n",
      "1032/1032 [==============================] - 0s 52us/sample - loss: 1.0154 - accuracy: 0.5029 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 303/500\n",
      "1032/1032 [==============================] - 0s 46us/sample - loss: 1.0146 - accuracy: 0.5000 - val_loss: 0.9723 - val_accuracy: 0.5946\n",
      "Epoch 304/500\n",
      "1032/1032 [==============================] - 0s 33us/sample - loss: 1.0147 - accuracy: 0.5029 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 305/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0155 - accuracy: 0.4990 - val_loss: 0.9706 - val_accuracy: 0.5946\n",
      "Epoch 306/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0150 - accuracy: 0.5019 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 307/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0148 - accuracy: 0.5029 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 308/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0154 - accuracy: 0.5019 - val_loss: 0.9707 - val_accuracy: 0.5985\n",
      "Epoch 309/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0144 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 310/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0143 - accuracy: 0.5010 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 311/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0148 - accuracy: 0.5010 - val_loss: 0.9721 - val_accuracy: 0.5985\n",
      "Epoch 312/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0149 - accuracy: 0.5010 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 313/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0142 - accuracy: 0.5039 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 314/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0144 - accuracy: 0.5029 - val_loss: 0.9707 - val_accuracy: 0.5985\n",
      "Epoch 315/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0147 - accuracy: 0.4990 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 316/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0149 - accuracy: 0.5010 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 317/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0144 - accuracy: 0.5019 - val_loss: 0.9712 - val_accuracy: 0.5946\n",
      "Epoch 318/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0149 - accuracy: 0.4990 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 319/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9729 - val_accuracy: 0.5946\n",
      "Epoch 320/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0143 - accuracy: 0.5039 - val_loss: 0.9708 - val_accuracy: 0.5946\n",
      "Epoch 321/500\n",
      "1032/1032 [==============================] - 0s 33us/sample - loss: 1.0160 - accuracy: 0.4971 - val_loss: 0.9705 - val_accuracy: 0.5985\n",
      "Epoch 322/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0155 - accuracy: 0.4971 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 323/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9709 - val_accuracy: 0.5985\n",
      "Epoch 324/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0143 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5985\n",
      "Epoch 325/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0152 - accuracy: 0.5000 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 326/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0150 - accuracy: 0.5039 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 327/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0141 - accuracy: 0.5039 - val_loss: 0.9735 - val_accuracy: 0.5946\n",
      "Epoch 328/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0145 - accuracy: 0.5010 - val_loss: 0.9714 - val_accuracy: 0.5946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0145 - accuracy: 0.5019 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 330/500\n",
      "1032/1032 [==============================] - 0s 51us/sample - loss: 1.0172 - accuracy: 0.4990 - val_loss: 0.9746 - val_accuracy: 0.5946\n",
      "Epoch 331/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0157 - accuracy: 0.5029 - val_loss: 0.9710 - val_accuracy: 0.5869\n",
      "Epoch 332/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0160 - accuracy: 0.5039 - val_loss: 0.9734 - val_accuracy: 0.5946\n",
      "Epoch 333/500\n",
      "1032/1032 [==============================] - 0s 33us/sample - loss: 1.0148 - accuracy: 0.5010 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 334/500\n",
      "1032/1032 [==============================] - 0s 33us/sample - loss: 1.0158 - accuracy: 0.5029 - val_loss: 0.9747 - val_accuracy: 0.5946\n",
      "Epoch 335/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0155 - accuracy: 0.5039 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 336/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0146 - accuracy: 0.5019 - val_loss: 0.9717 - val_accuracy: 0.5985\n",
      "Epoch 337/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0142 - accuracy: 0.5019 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 338/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0146 - accuracy: 0.4990 - val_loss: 0.9710 - val_accuracy: 0.5985\n",
      "Epoch 339/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0155 - accuracy: 0.5029 - val_loss: 0.9749 - val_accuracy: 0.5946\n",
      "Epoch 340/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0148 - accuracy: 0.5048 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 341/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0149 - accuracy: 0.4990 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 342/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0143 - accuracy: 0.5029 - val_loss: 0.9734 - val_accuracy: 0.5946\n",
      "Epoch 343/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0150 - accuracy: 0.5039 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 344/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0142 - accuracy: 0.5019 - val_loss: 0.9708 - val_accuracy: 0.5985\n",
      "Epoch 345/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0153 - accuracy: 0.5010 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 346/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0145 - accuracy: 0.5029 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 347/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0144 - accuracy: 0.5029 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 348/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0145 - accuracy: 0.5029 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 349/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0145 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 350/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0157 - accuracy: 0.5039 - val_loss: 0.9729 - val_accuracy: 0.5946\n",
      "Epoch 351/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0153 - accuracy: 0.5039 - val_loss: 0.9704 - val_accuracy: 0.5946\n",
      "Epoch 352/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0146 - accuracy: 0.5000 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 353/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0159 - accuracy: 0.5019 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 354/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0178 - accuracy: 0.5010 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 355/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0147 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 356/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0147 - accuracy: 0.4990 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 357/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0145 - accuracy: 0.5048 - val_loss: 0.9715 - val_accuracy: 0.5985\n",
      "Epoch 358/500\n",
      "1032/1032 [==============================] - 0s 52us/sample - loss: 1.0139 - accuracy: 0.5048 - val_loss: 0.9726 - val_accuracy: 0.5946\n",
      "Epoch 359/500\n",
      "1032/1032 [==============================] - 0s 47us/sample - loss: 1.0147 - accuracy: 0.4990 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 360/500\n",
      "1032/1032 [==============================] - 0s 32us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9701 - val_accuracy: 0.5907\n",
      "Epoch 361/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0151 - accuracy: 0.5010 - val_loss: 0.9718 - val_accuracy: 0.5946\n",
      "Epoch 362/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0145 - accuracy: 0.5010 - val_loss: 0.9707 - val_accuracy: 0.5946\n",
      "Epoch 363/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0145 - accuracy: 0.4981 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 364/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0173 - accuracy: 0.5039 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 365/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0143 - accuracy: 0.5019 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 366/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0153 - accuracy: 0.5019 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 367/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0147 - accuracy: 0.5029 - val_loss: 0.9712 - val_accuracy: 0.5946\n",
      "Epoch 368/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0145 - accuracy: 0.5000 - val_loss: 0.9718 - val_accuracy: 0.5985\n",
      "Epoch 369/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0148 - accuracy: 0.5029 - val_loss: 0.9719 - val_accuracy: 0.5985\n",
      "Epoch 370/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 371/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0158 - accuracy: 0.5000 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 372/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0141 - accuracy: 0.5078 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 373/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0152 - accuracy: 0.4971 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 374/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0158 - accuracy: 0.5068 - val_loss: 0.9709 - val_accuracy: 0.5946\n",
      "Epoch 375/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0159 - accuracy: 0.5039 - val_loss: 0.9732 - val_accuracy: 0.5946\n",
      "Epoch 376/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0152 - accuracy: 0.5010 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 377/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0152 - accuracy: 0.5048 - val_loss: 0.9700 - val_accuracy: 0.5985\n",
      "Epoch 378/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0163 - accuracy: 0.5010 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 379/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0145 - accuracy: 0.5029 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 380/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0143 - accuracy: 0.5019 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 381/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 382/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0150 - accuracy: 0.5039 - val_loss: 0.9730 - val_accuracy: 0.5946\n",
      "Epoch 383/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0156 - accuracy: 0.5039 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 384/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0144 - accuracy: 0.5019 - val_loss: 0.9723 - val_accuracy: 0.5985\n",
      "Epoch 385/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0165 - accuracy: 0.4981 - val_loss: 0.9723 - val_accuracy: 0.5985\n",
      "Epoch 386/500\n",
      "1032/1032 [==============================] - 0s 55us/sample - loss: 1.0163 - accuracy: 0.5010 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 387/500\n",
      "1032/1032 [==============================] - 0s 48us/sample - loss: 1.0167 - accuracy: 0.5029 - val_loss: 0.9736 - val_accuracy: 0.5946\n",
      "Epoch 388/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0151 - accuracy: 0.5019 - val_loss: 0.9705 - val_accuracy: 0.5985\n",
      "Epoch 389/500\n",
      "1032/1032 [==============================] - 0s 32us/sample - loss: 1.0147 - accuracy: 0.4981 - val_loss: 0.9726 - val_accuracy: 0.5946\n",
      "Epoch 390/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0143 - accuracy: 0.5019 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 391/500\n",
      "1032/1032 [==============================] - 0s 33us/sample - loss: 1.0165 - accuracy: 0.4990 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 392/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0156 - accuracy: 0.5029 - val_loss: 0.9713 - val_accuracy: 0.5985\n",
      "Epoch 393/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0157 - accuracy: 0.5039 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 394/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0175 - accuracy: 0.5000 - val_loss: 0.9742 - val_accuracy: 0.5946\n",
      "Epoch 395/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0136 - accuracy: 0.5029 - val_loss: 0.9709 - val_accuracy: 0.5985\n",
      "Epoch 396/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0158 - accuracy: 0.5010 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 397/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0149 - accuracy: 0.5029 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 398/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0151 - accuracy: 0.5010 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 399/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0153 - accuracy: 0.5039 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 400/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0143 - accuracy: 0.5019 - val_loss: 0.9712 - val_accuracy: 0.5946\n",
      "Epoch 401/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0148 - accuracy: 0.4971 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 402/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0143 - accuracy: 0.5039 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 403/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0148 - accuracy: 0.5000 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 404/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0146 - accuracy: 0.5048 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 405/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0156 - accuracy: 0.5010 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 406/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0145 - accuracy: 0.5010 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 407/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0156 - accuracy: 0.5000 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 408/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0149 - accuracy: 0.5029 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 409/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0144 - accuracy: 0.5010 - val_loss: 0.9709 - val_accuracy: 0.5907\n",
      "Epoch 410/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0149 - accuracy: 0.5010 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 411/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0153 - accuracy: 0.5019 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 412/500\n",
      "1032/1032 [==============================] - 0s 82us/sample - loss: 1.0148 - accuracy: 0.5010 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 413/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0158 - accuracy: 0.4971 - val_loss: 0.9701 - val_accuracy: 0.5985\n",
      "Epoch 414/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0141 - accuracy: 0.5010 - val_loss: 0.9723 - val_accuracy: 0.5946\n",
      "Epoch 415/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0148 - accuracy: 0.5039 - val_loss: 0.9706 - val_accuracy: 0.5946\n",
      "Epoch 416/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0145 - accuracy: 0.5058 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 417/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0139 - accuracy: 0.5010 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 418/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0142 - accuracy: 0.5019 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 419/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0148 - accuracy: 0.5010 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 420/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0152 - accuracy: 0.5019 - val_loss: 0.9704 - val_accuracy: 0.5985\n",
      "Epoch 421/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0161 - accuracy: 0.4961 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 422/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0149 - accuracy: 0.5058 - val_loss: 0.9729 - val_accuracy: 0.5946\n",
      "Epoch 423/500\n",
      "1032/1032 [==============================] - 0s 45us/sample - loss: 1.0154 - accuracy: 0.5068 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 424/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0161 - accuracy: 0.4990 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 425/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0146 - accuracy: 0.5029 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 426/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0152 - accuracy: 0.5019 - val_loss: 0.9729 - val_accuracy: 0.5946\n",
      "Epoch 427/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0177 - accuracy: 0.4990 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 428/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0154 - accuracy: 0.5058 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 429/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0139 - accuracy: 0.5019 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 430/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0145 - accuracy: 0.5019 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 431/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0150 - accuracy: 0.5048 - val_loss: 0.9710 - val_accuracy: 0.5907\n",
      "Epoch 432/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0162 - accuracy: 0.5010 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 433/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0144 - accuracy: 0.5010 - val_loss: 0.9708 - val_accuracy: 0.5946\n",
      "Epoch 434/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0143 - accuracy: 0.5039 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 435/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0155 - accuracy: 0.5048 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 436/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0163 - accuracy: 0.5010 - val_loss: 0.9719 - val_accuracy: 0.5946\n",
      "Epoch 437/500\n",
      "1032/1032 [==============================] - 0s 84us/sample - loss: 1.0147 - accuracy: 0.5039 - val_loss: 0.9716 - val_accuracy: 0.5946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0146 - accuracy: 0.5039 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 439/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0151 - accuracy: 0.4990 - val_loss: 0.9712 - val_accuracy: 0.5946\n",
      "Epoch 440/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0142 - accuracy: 0.5019 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 441/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0147 - accuracy: 0.5087 - val_loss: 0.9710 - val_accuracy: 0.5946\n",
      "Epoch 442/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0188 - accuracy: 0.4990 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 443/500\n",
      "1032/1032 [==============================] - 0s 41us/sample - loss: 1.0167 - accuracy: 0.5039 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 444/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0144 - accuracy: 0.5000 - val_loss: 0.9737 - val_accuracy: 0.5946\n",
      "Epoch 445/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0193 - accuracy: 0.5010 - val_loss: 0.9704 - val_accuracy: 0.5869\n",
      "Epoch 446/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0146 - accuracy: 0.5029 - val_loss: 0.9730 - val_accuracy: 0.5946\n",
      "Epoch 447/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0160 - accuracy: 0.5010 - val_loss: 0.9709 - val_accuracy: 0.5907\n",
      "Epoch 448/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0136 - accuracy: 0.5039 - val_loss: 0.9739 - val_accuracy: 0.5946\n",
      "Epoch 449/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0152 - accuracy: 0.5039 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 450/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0173 - accuracy: 0.4981 - val_loss: 0.9712 - val_accuracy: 0.5985\n",
      "Epoch 451/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0149 - accuracy: 0.5058 - val_loss: 0.9727 - val_accuracy: 0.5946\n",
      "Epoch 452/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0148 - accuracy: 0.5048 - val_loss: 0.9714 - val_accuracy: 0.5946\n",
      "Epoch 453/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0145 - accuracy: 0.5068 - val_loss: 0.9726 - val_accuracy: 0.5946\n",
      "Epoch 454/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0148 - accuracy: 0.5048 - val_loss: 0.9702 - val_accuracy: 0.5946\n",
      "Epoch 455/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0146 - accuracy: 0.5039 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 456/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0148 - accuracy: 0.5000 - val_loss: 0.9711 - val_accuracy: 0.5907\n",
      "Epoch 457/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0143 - accuracy: 0.5010 - val_loss: 0.9712 - val_accuracy: 0.5946\n",
      "Epoch 458/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0142 - accuracy: 0.5019 - val_loss: 0.9716 - val_accuracy: 0.5946\n",
      "Epoch 459/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0150 - accuracy: 0.5010 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 460/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0146 - accuracy: 0.5039 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 461/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0142 - accuracy: 0.5010 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 462/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0148 - accuracy: 0.5000 - val_loss: 0.9711 - val_accuracy: 0.5985\n",
      "Epoch 463/500\n",
      "1032/1032 [==============================] - 0s 63us/sample - loss: 1.0140 - accuracy: 0.5010 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 464/500\n",
      "1032/1032 [==============================] - 0s 43us/sample - loss: 1.0161 - accuracy: 0.5048 - val_loss: 0.9710 - val_accuracy: 0.5830\n",
      "Epoch 465/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0166 - accuracy: 0.5019 - val_loss: 0.9712 - val_accuracy: 0.5907\n",
      "Epoch 466/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0175 - accuracy: 0.5039 - val_loss: 0.9701 - val_accuracy: 0.5907\n",
      "Epoch 467/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0150 - accuracy: 0.4961 - val_loss: 0.9732 - val_accuracy: 0.5946\n",
      "Epoch 468/500\n",
      "1032/1032 [==============================] - 0s 35us/sample - loss: 1.0152 - accuracy: 0.5048 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 469/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0158 - accuracy: 0.4981 - val_loss: 0.9726 - val_accuracy: 0.5946\n",
      "Epoch 470/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0146 - accuracy: 0.5039 - val_loss: 0.9713 - val_accuracy: 0.5907\n",
      "Epoch 471/500\n",
      "1032/1032 [==============================] - 0s 55us/sample - loss: 1.0191 - accuracy: 0.5078 - val_loss: 0.9734 - val_accuracy: 0.5946\n",
      "Epoch 472/500\n",
      "1032/1032 [==============================] - 0s 44us/sample - loss: 1.0162 - accuracy: 0.5019 - val_loss: 0.9717 - val_accuracy: 0.5946\n",
      "Epoch 473/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0157 - accuracy: 0.5010 - val_loss: 0.9745 - val_accuracy: 0.5946\n",
      "Epoch 474/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0146 - accuracy: 0.5010 - val_loss: 0.9710 - val_accuracy: 0.5907\n",
      "Epoch 475/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0140 - accuracy: 0.5019 - val_loss: 0.9715 - val_accuracy: 0.5946\n",
      "Epoch 476/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0142 - accuracy: 0.5039 - val_loss: 0.9722 - val_accuracy: 0.5946\n",
      "Epoch 477/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0142 - accuracy: 0.5010 - val_loss: 0.9724 - val_accuracy: 0.5946\n",
      "Epoch 478/500\n",
      "1032/1032 [==============================] - 0s 40us/sample - loss: 1.0145 - accuracy: 0.4981 - val_loss: 0.9709 - val_accuracy: 0.5985\n",
      "Epoch 479/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0139 - accuracy: 0.5068 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 480/500\n",
      "1032/1032 [==============================] - 0s 39us/sample - loss: 1.0140 - accuracy: 0.5029 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 481/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0143 - accuracy: 0.5048 - val_loss: 0.9712 - val_accuracy: 0.5907\n",
      "Epoch 482/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0148 - accuracy: 0.5039 - val_loss: 0.9738 - val_accuracy: 0.5946\n",
      "Epoch 483/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0145 - accuracy: 0.5000 - val_loss: 0.9704 - val_accuracy: 0.5946\n",
      "Epoch 484/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0141 - accuracy: 0.5058 - val_loss: 0.9713 - val_accuracy: 0.5946\n",
      "Epoch 485/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0143 - accuracy: 0.5010 - val_loss: 0.9718 - val_accuracy: 0.5907\n",
      "Epoch 486/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0146 - accuracy: 0.5039 - val_loss: 0.9719 - val_accuracy: 0.5907\n",
      "Epoch 487/500\n",
      "1032/1032 [==============================] - 0s 38us/sample - loss: 1.0140 - accuracy: 0.5029 - val_loss: 0.9720 - val_accuracy: 0.5946\n",
      "Epoch 488/500\n",
      "1032/1032 [==============================] - 0s 42us/sample - loss: 1.0140 - accuracy: 0.5029 - val_loss: 0.9706 - val_accuracy: 0.5946\n",
      "Epoch 489/500\n",
      "1032/1032 [==============================] - 0s 69us/sample - loss: 1.0155 - accuracy: 0.5019 - val_loss: 0.9708 - val_accuracy: 0.5907\n",
      "Epoch 490/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0171 - accuracy: 0.5029 - val_loss: 0.9707 - val_accuracy: 0.5985\n",
      "Epoch 491/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0184 - accuracy: 0.5010 - val_loss: 0.9738 - val_accuracy: 0.5946\n",
      "Epoch 492/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0138 - accuracy: 0.5039 - val_loss: 0.9704 - val_accuracy: 0.5985\n",
      "Epoch 493/500\n",
      "1032/1032 [==============================] - 0s 34us/sample - loss: 1.0153 - accuracy: 0.5000 - val_loss: 0.9723 - val_accuracy: 0.5946\n",
      "Epoch 494/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0150 - accuracy: 0.5058 - val_loss: 0.9699 - val_accuracy: 0.5985\n",
      "Epoch 495/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0146 - accuracy: 0.4990 - val_loss: 0.9729 - val_accuracy: 0.5946\n",
      "Epoch 496/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0146 - accuracy: 0.5068 - val_loss: 0.9721 - val_accuracy: 0.5946\n",
      "Epoch 497/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0146 - accuracy: 0.5039 - val_loss: 0.9711 - val_accuracy: 0.5946\n",
      "Epoch 498/500\n",
      "1032/1032 [==============================] - 0s 37us/sample - loss: 1.0157 - accuracy: 0.5010 - val_loss: 0.9704 - val_accuracy: 0.5907\n",
      "Epoch 499/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0198 - accuracy: 0.4952 - val_loss: 0.9725 - val_accuracy: 0.5946\n",
      "Epoch 500/500\n",
      "1032/1032 [==============================] - 0s 36us/sample - loss: 1.0150 - accuracy: 0.5029 - val_loss: 0.9711 - val_accuracy: 0.5907\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,validation_data=(x_test, y_test),batch_size=50,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'],label='Accuracy')#bleu\n",
    "plt.plot(history.history['val_accuracy'],label='validation_Accuracy')#orange\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4803 7447    0    1    0    0]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_test[25])\n",
    "print(y_test[25])\n",
    "plt.show()\n",
    "np.argmax(predictions[25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrÃ©diction Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "puissance_homeTeam = 3029\n",
    "puissance_awayTeam = 2045\n",
    "win_cons_home = -1\n",
    "win_cons_away = 0\n",
    "lose_cons_home = 2\n",
    "lose_cons_away= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La HomeTeam va gagner contre l'Awayteam\n"
     ]
    }
   ],
   "source": [
    "predictions1 = model.predict(np.array([[puissance_homeTeam,puissance_awayTeam,win_cons_home,win_cons_away,lose_cons_home,lose_cons_away]])) # predictions avec puissance de teams au hasard\n",
    "result = np.argmax(predictions1)\n",
    "if result == 0:\n",
    "    print(\"La HomeTeam va Ã©galiser contre l'Awayteam\")\n",
    "if result == 1:\n",
    "    print(\"La HomeTeam va gagner contre l'Awayteam\")\n",
    "if result == 2:\n",
    "    print(\"La HomeTeam va perdre contre l'Awayteam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
